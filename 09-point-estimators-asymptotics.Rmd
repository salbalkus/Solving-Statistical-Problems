# Point Estimators: Asymptotics {#point-estimators-asymptotics}

Evaluating the asymptotic properties of point estimators.

## Consistency

An important asymptotic property of an estimator is that it converges in probability to the true value being estimated as $n \rightarrow \infty$. This is called **consistency**. 

One strategy for proving consistency is to use the Weak Law of Large Numbers.

::: {#wlln .theorem name = "Weak Law of Large Numbers"}

**iid version**: If $Z_i$ are iid with finite mean, then

$$\bar{X} = \frac{1}{n}\sum_{i=1}^nX_i\overset{p}{\rightarrow}E(X_i)$$

**Non-iid version**: Alternatively, we can drop the iid assumption; if $X_i$ have finite mean and variance, $Cov(X_i, X_j) = 0$, and $\lim_{n\rightarrow\infty}\sum_{i=1}^n\frac{\sigma_i^2}{n^2} = 0$, then

$$\frac{1}{n}\sum_{i=1}^nX_i - \frac{1}{n}\sum_{i=1}^nE(X_i) \overset{\mathcal{p}}{\rightarrow} 0$$
:::

The WLLN can be combined with the Continuous Mapping Theorem to show a variety of estimators are consistent.

## Asymptotic Normality

### Central Limit Theorems


::: {#clt .theorem name = "Central Limit Theorem (iid)"}

If $X_i$ are iid with finite first and second moments ($E(X_i), Var(X_i) < \infty$)  then

$$\sqrt{n}\Big(\frac{1}{n}\sum_{i=1}^nX_i - E(X_i)\Big) \overset{\mathcal{D}}{\rightarrow} N(0,Var(X_i))$$

:::

::: {#clt .theorem name = "Lyapunov's Central Limit Theorem (non-iid)"}

Consider $X_i$ that are independent with finite first and second moments ($E(X_i), Var(X_i) < \infty$). Let $S_n^2 = \sum_{i=1}^n Var(X_i)$. Then, for some $\delta > 0$, if the condition

$$\lim_{n\rightarrow \infty} \frac{1}{S_n^{2 + \delta}}\sum_{i=1}^n E(|X_i - E(X_i)|^{2 + \delta}) = 0$$

holds, then we know

$$\frac{1}{S_n}\sum_{i=1}^n (X_i - E(X_i)) \overset{\mathcal{D}}{\rightarrow} N(0,1)$$
:::

In practice, to prove that Lyapunov's CLT holds true, we typically take $\delta = 1$ and compute the third moments contained in the Lyapunov condition. Alternatively, we can use Lindeberg's CLT for non-iid data:

::: {#clt .theorem name = "Lindeberg's Central Limit Theorem (non-iid)"}
Like the Lyapunov CLT, consider $X_i$ that are independent with finite first and second moments ($E(X_i), Var(X_i) < \infty$). Let $S_n^2 = \sum_{i=1}^n Var(X_i)$. Then if

$$\lim_{n\rightarrow \infty} \frac{1}{S_n^{2}}\sum_{i=1}^n E((X_i - E(X_i))^{2})\cdot I(|X_i - E(X_i) > \varepsilon S_n) = 0$$
holds, then we know

$$\frac{1}{S_n}\sum_{i=1}^n (X_i - E(X_i)) \overset{\mathcal{D}}{\rightarrow} N(0,1)$$

:::


### The Delta Method

:::{#delta-method .theorem name="Delta Method"}

If $\sqrt{n}(\hat{\theta}_n - \theta) \overset{\mathcal{D}}{\rightarrow} N(0,\sigma^2)$, then for a continuous $g$ with continuous nonzero derivative in an interval containing $\theta$...

- $\sqrt{n}\Big(g(\hat{\theta}_n) - g(\theta)\Big) \overset{\mathcal{D}}{\rightarrow} N\Big(0, \sigma^2\cdot (\frac{d}{d\theta}g(\theta))^2\Big)$ (First-Order Delta Method)
- $n\Big(g(\hat{\theta}_n) - g(\theta)\Big) \overset{\mathcal{D}}{\rightarrow} \frac{1}{2}\sigma^2\cdot g''(\theta)\cdot\chi^2(1)$ (Second-Order Delta Method)

:::

Generally, the Second-Order Delta Method is required if $g'(\theta) = 0$.

:::{#delta-method .theorem name="Multivariate Delta Method"}

If $\sqrt{n}(\hat{\theta}_n - \theta) \overset{\mathcal{D}}{\rightarrow} N(0,V)$, where $V$ is a $k \times k$ matrix, then for a continuous real-valued function $g(x)$ of $k$ variables with continuous nonzero first partial derivatives,

$$\sqrt{n}\Big(g(\hat{\theta}_n) - g(\theta)\Big) \overset{\mathcal{D}}{\rightarrow} MVN_k\Big(0, u'Vu\Big)$$

where $u = \begin{bmatrix}\frac{\partial}{\partial \theta_1}g(\theta),...,\frac{\partial}{\partial \theta_k}g(\theta)\end{bmatrix}$

:::


