<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Hypothesis Tests: Finite Samples | Solving Statistical Problems</title>
  <meta name="description" content="Chapter 10 Hypothesis Tests: Finite Samples | Solving Statistical Problems" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Hypothesis Tests: Finite Samples | Solving Statistical Problems" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 10 Hypothesis Tests: Finite Samples | Solving Statistical Problems" />
  <meta name="github-repo" content="salbalkus/Solving-Statistical-Problems" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Hypothesis Tests: Finite Samples | Solving Statistical Problems" />
  
  <meta name="twitter:description" content="Chapter 10 Hypothesis Tests: Finite Samples | Solving Statistical Problems" />
  

<meta name="author" content="Salvador Balkus, Kimberly Greco, and Mónica Robles Fontán" />


<meta name="date" content="2023-08-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="point-estimators-asymptotics.html"/>
<link rel="next" href="hypothesis-tests-asymptotics.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Solving Statistical Problems</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="math-tricks.html"><a href="math-tricks.html"><i class="fa fa-check"></i><b>2</b> Math Tricks</a>
<ul>
<li class="chapter" data-level="2.1" data-path="math-tricks.html"><a href="math-tricks.html#combinatorics"><i class="fa fa-check"></i><b>2.1</b> Combinatorics</a></li>
<li class="chapter" data-level="2.2" data-path="math-tricks.html"><a href="math-tricks.html#binomial-and-multinomial-theorems"><i class="fa fa-check"></i><b>2.2</b> Binomial and Multinomial Theorems</a></li>
<li class="chapter" data-level="2.3" data-path="math-tricks.html"><a href="math-tricks.html#geometric-series"><i class="fa fa-check"></i><b>2.3</b> Geometric Series</a></li>
<li class="chapter" data-level="2.4" data-path="math-tricks.html"><a href="math-tricks.html#exponential-taylor"><i class="fa fa-check"></i><b>2.4</b> Taylor Series for Exponential Function</a></li>
<li class="chapter" data-level="2.5" data-path="math-tricks.html"><a href="math-tricks.html#taylors-formula"><i class="fa fa-check"></i><b>2.5</b> Taylor’s Formula</a></li>
<li class="chapter" data-level="2.6" data-path="math-tricks.html"><a href="math-tricks.html#exponential-limit"><i class="fa fa-check"></i><b>2.6</b> Exponential Limit</a></li>
<li class="chapter" data-level="2.7" data-path="math-tricks.html"><a href="math-tricks.html#ibp"><i class="fa fa-check"></i><b>2.7</b> Integration by Parts</a></li>
<li class="chapter" data-level="2.8" data-path="math-tricks.html"><a href="math-tricks.html#leibniz-rule"><i class="fa fa-check"></i><b>2.8</b> Leibniz’s Rule</a></li>
<li class="chapter" data-level="2.9" data-path="math-tricks.html"><a href="math-tricks.html#fubinis-theorem"><i class="fa fa-check"></i><b>2.9</b> Fubini’s Theorem</a></li>
<li class="chapter" data-level="2.10" data-path="math-tricks.html"><a href="math-tricks.html#gamma-function"><i class="fa fa-check"></i><b>2.10</b> Gamma Function</a></li>
<li class="chapter" data-level="2.11" data-path="math-tricks.html"><a href="math-tricks.html#triangle-inequality"><i class="fa fa-check"></i><b>2.11</b> Triangle Inequality</a></li>
<li class="chapter" data-level="2.12" data-path="math-tricks.html"><a href="math-tricks.html#constrained-optimization"><i class="fa fa-check"></i><b>2.12</b> Constrained Optimization</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#basic-axioms"><i class="fa fa-check"></i><b>3.1</b> Basic Axioms</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#basic-probability-solving-techniques"><i class="fa fa-check"></i><b>3.2</b> Basic Probability Solving Techniques</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#disjointify"><i class="fa fa-check"></i><b>3.2.1</b> Disjointification</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#demorgan"><i class="fa fa-check"></i><b>3.2.2</b> DeMorgan’s Laws</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#proving-inequalities-subsetting"><i class="fa fa-check"></i><b>3.2.3</b> Proving Inequalities: Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>3.3</b> Conditional Probability</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="probability.html"><a href="probability.html#conditional-probability-in-practice"><i class="fa fa-check"></i><b>3.3.1</b> Conditional Probability in Practice</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#random-variables"><i class="fa fa-check"></i><b>3.4</b> Random Variables</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability.html"><a href="probability.html#definition"><i class="fa fa-check"></i><b>3.4.1</b> Definition</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability.html"><a href="probability.html#functions-describing-the-distribution"><i class="fa fa-check"></i><b>3.4.2</b> Functions Describing the Distribution</a></li>
<li class="chapter" data-level="3.4.3" data-path="probability.html"><a href="probability.html#direct-manipulation"><i class="fa fa-check"></i><b>3.4.3</b> Technique: Direct Probability Manipulation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>3.5</b> Independence</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#order-statistics"><i class="fa fa-check"></i><b>3.6</b> Order Statistics</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#convergence"><i class="fa fa-check"></i><b>3.7</b> Convergence</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="probability.html"><a href="probability.html#borel-cantelli-lemmas"><i class="fa fa-check"></i><b>3.7.1</b> Borel-Cantelli Lemmas</a></li>
<li class="chapter" data-level="3.7.2" data-path="probability.html"><a href="probability.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.7.2</b> Convergence in Probability</a></li>
<li class="chapter" data-level="3.7.3" data-path="probability.html"><a href="probability.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.7.3</b> Convergence in Distribution</a></li>
<li class="chapter" data-level="3.7.4" data-path="probability.html"><a href="probability.html#important-theorems"><i class="fa fa-check"></i><b>3.7.4</b> Important Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="known-distributions.html"><a href="known-distributions.html"><i class="fa fa-check"></i><b>4</b> Known Distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="known-distributions.html"><a href="known-distributions.html#families-of-distributions"><i class="fa fa-check"></i><b>4.1</b> Families of Distributions</a></li>
<li class="chapter" data-level="4.2" data-path="known-distributions.html"><a href="known-distributions.html#location-scale"><i class="fa fa-check"></i><b>4.2</b> Location and Scale Families</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="known-distributions.html"><a href="known-distributions.html#location-families"><i class="fa fa-check"></i><b>4.2.1</b> Location Families</a></li>
<li class="chapter" data-level="4.2.2" data-path="known-distributions.html"><a href="known-distributions.html#scale-families"><i class="fa fa-check"></i><b>4.2.2</b> Scale Families</a></li>
<li class="chapter" data-level="4.2.3" data-path="known-distributions.html"><a href="known-distributions.html#properties-of-location-scale-families"><i class="fa fa-check"></i><b>4.2.3</b> Properties of Location-Scale Families</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="known-distributions.html"><a href="known-distributions.html#exponential-family"><i class="fa fa-check"></i><b>4.3</b> Exponential Families</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="known-distributions.html"><a href="known-distributions.html#properties"><i class="fa fa-check"></i><b>4.3.1</b> Properties</a></li>
<li class="chapter" data-level="4.3.2" data-path="known-distributions.html"><a href="known-distributions.html#natural-exponential-family"><i class="fa fa-check"></i><b>4.3.2</b> Natural Exponential Families</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="known-distributions.html"><a href="known-distributions.html#known-univariate-exponential-families"><i class="fa fa-check"></i><b>4.4</b> Known Univariate Exponential Families</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="known-distributions.html"><a href="known-distributions.html#bernoulli"><i class="fa fa-check"></i><b>4.4.1</b> Bernoulli</a></li>
<li class="chapter" data-level="4.4.2" data-path="known-distributions.html"><a href="known-distributions.html#binomial"><i class="fa fa-check"></i><b>4.4.2</b> Binomial</a></li>
<li class="chapter" data-level="4.4.3" data-path="known-distributions.html"><a href="known-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>4.4.3</b> Geometric</a></li>
<li class="chapter" data-level="4.4.4" data-path="known-distributions.html"><a href="known-distributions.html#negative-binomial"><i class="fa fa-check"></i><b>4.4.4</b> Negative Binomial</a></li>
<li class="chapter" data-level="4.4.5" data-path="known-distributions.html"><a href="known-distributions.html#poisson"><i class="fa fa-check"></i><b>4.4.5</b> Poisson</a></li>
<li class="chapter" data-level="4.4.6" data-path="known-distributions.html"><a href="known-distributions.html#normal"><i class="fa fa-check"></i><b>4.4.6</b> Normal</a></li>
<li class="chapter" data-level="4.4.7" data-path="known-distributions.html"><a href="known-distributions.html#exponential"><i class="fa fa-check"></i><b>4.4.7</b> Exponential</a></li>
<li class="chapter" data-level="4.4.8" data-path="known-distributions.html"><a href="known-distributions.html#gamma"><i class="fa fa-check"></i><b>4.4.8</b> Gamma</a></li>
<li class="chapter" data-level="4.4.9" data-path="known-distributions.html"><a href="known-distributions.html#beta"><i class="fa fa-check"></i><b>4.4.9</b> Beta</a></li>
<li class="chapter" data-level="4.4.10" data-path="known-distributions.html"><a href="known-distributions.html#chi-squared"><i class="fa fa-check"></i><b>4.4.10</b> Chi-squared</a></li>
<li class="chapter" data-level="4.4.11" data-path="known-distributions.html"><a href="known-distributions.html#weibull"><i class="fa fa-check"></i><b>4.4.11</b> Weibull</a></li>
<li class="chapter" data-level="4.4.12" data-path="known-distributions.html"><a href="known-distributions.html#pareto"><i class="fa fa-check"></i><b>4.4.12</b> Pareto</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="known-distributions.html"><a href="known-distributions.html#non-exponential-families"><i class="fa fa-check"></i><b>4.5</b> Non-exponential families</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="known-distributions.html"><a href="known-distributions.html#uniform"><i class="fa fa-check"></i><b>4.5.1</b> Uniform</a></li>
<li class="chapter" data-level="4.5.2" data-path="known-distributions.html"><a href="known-distributions.html#cauchy"><i class="fa fa-check"></i><b>4.5.2</b> Cauchy</a></li>
<li class="chapter" data-level="4.5.3" data-path="known-distributions.html"><a href="known-distributions.html#studentst"><i class="fa fa-check"></i><b>4.5.3</b> t-distribution</a></li>
<li class="chapter" data-level="4.5.4" data-path="known-distributions.html"><a href="known-distributions.html#f-distribution"><i class="fa fa-check"></i><b>4.5.4</b> F-distribution</a></li>
<li class="chapter" data-level="4.5.5" data-path="known-distributions.html"><a href="known-distributions.html#hypergeometric"><i class="fa fa-check"></i><b>4.5.5</b> Hypergeometric</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="known-distributions.html"><a href="known-distributions.html#multivariate-distributions"><i class="fa fa-check"></i><b>4.6</b> Multivariate Distributions</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="known-distributions.html"><a href="known-distributions.html#bivariate-normal"><i class="fa fa-check"></i><b>4.6.1</b> Bivariate Normal</a></li>
<li class="chapter" data-level="4.6.2" data-path="known-distributions.html"><a href="known-distributions.html#multivariate-normal"><i class="fa fa-check"></i><b>4.6.2</b> Multivariate Normal</a></li>
<li class="chapter" data-level="4.6.3" data-path="known-distributions.html"><a href="known-distributions.html#multinomial"><i class="fa fa-check"></i><b>4.6.3</b> Multinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="known-distributions.html"><a href="known-distributions.html#medians-and-other-functionals-of-a-distribution"><i class="fa fa-check"></i><b>4.7</b> Medians and Other Functionals of a Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="new-distributions.html"><a href="new-distributions.html"><i class="fa fa-check"></i><b>5</b> New Distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="new-distributions.html"><a href="new-distributions.html#transformations"><i class="fa fa-check"></i><b>5.1</b> Transformations</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="new-distributions.html"><a href="new-distributions.html#theorems"><i class="fa fa-check"></i><b>5.1.1</b> Theorems</a></li>
<li class="chapter" data-level="5.1.2" data-path="new-distributions.html"><a href="new-distributions.html#practical-strategy"><i class="fa fa-check"></i><b>5.1.2</b> Practical Strategy</a></li>
<li class="chapter" data-level="5.1.3" data-path="new-distributions.html"><a href="new-distributions.html#proving-independence-from-a-joint-transformation"><i class="fa fa-check"></i><b>5.1.3</b> Proving Independence From a Joint Transformation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="new-distributions.html"><a href="new-distributions.html#computing-joint-probabilities"><i class="fa fa-check"></i><b>5.2</b> Computing Joint Probabilities</a></li>
<li class="chapter" data-level="5.3" data-path="new-distributions.html"><a href="new-distributions.html#probability-integral-transform"><i class="fa fa-check"></i><b>5.3</b> Probability Integral Transform</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="new-distributions.html"><a href="new-distributions.html#hierarchical-models-iterated-moments"><i class="fa fa-check"></i><b>5.3.1</b> Hierarchical Models (Iterated Moments)</a></li>
<li class="chapter" data-level="5.3.2" data-path="new-distributions.html"><a href="new-distributions.html#convolutions"><i class="fa fa-check"></i><b>5.3.2</b> Convolutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="moments.html"><a href="moments.html"><i class="fa fa-check"></i><b>6</b> Moments</a>
<ul>
<li class="chapter" data-level="6.1" data-path="moments.html"><a href="moments.html#basic-definitions"><i class="fa fa-check"></i><b>6.1</b> Basic Definitions</a></li>
<li class="chapter" data-level="6.2" data-path="moments.html"><a href="moments.html#expected-value"><i class="fa fa-check"></i><b>6.2</b> <span class="math inline">\(E(X)\)</span> Properties</a></li>
<li class="chapter" data-level="6.3" data-path="moments.html"><a href="moments.html#varx-properties"><i class="fa fa-check"></i><b>6.3</b> <span class="math inline">\(Var(X)\)</span> Properties</a></li>
<li class="chapter" data-level="6.4" data-path="moments.html"><a href="moments.html#covariance-and-correlation"><i class="fa fa-check"></i><b>6.4</b> Covariance and Correlation</a></li>
<li class="chapter" data-level="6.5" data-path="moments.html"><a href="moments.html#conditional-expectation"><i class="fa fa-check"></i><b>6.5</b> Conditional Expectation</a></li>
<li class="chapter" data-level="6.6" data-path="moments.html"><a href="moments.html#mgf"><i class="fa fa-check"></i><b>6.6</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="6.7" data-path="moments.html"><a href="moments.html#moment-bounds"><i class="fa fa-check"></i><b>6.7</b> Moment Inequalities</a></li>
<li class="chapter" data-level="6.8" data-path="moments.html"><a href="moments.html#techniques-for-deriving-moments"><i class="fa fa-check"></i><b>6.8</b> Techniques for Deriving Moments</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="moments.html"><a href="moments.html#bernoulli-direct-summation"><i class="fa fa-check"></i><b>6.8.1</b> Bernoulli: Direct Summation</a></li>
<li class="chapter" data-level="6.8.2" data-path="moments.html"><a href="moments.html#uniform-direct-integration"><i class="fa fa-check"></i><b>6.8.2</b> Uniform: Direct Integration</a></li>
<li class="chapter" data-level="6.8.3" data-path="moments.html"><a href="moments.html#geometric-series-convergence"><i class="fa fa-check"></i><b>6.8.3</b> Geometric: Series Convergence</a></li>
<li class="chapter" data-level="6.8.4" data-path="moments.html"><a href="moments.html#binomial-kernel-technique-series-version"><i class="fa fa-check"></i><b>6.8.4</b> Binomial: Kernel Technique, Series Version</a></li>
<li class="chapter" data-level="6.8.5" data-path="moments.html"><a href="moments.html#negative-binomial-and-hypergeometric-computing-exx-1"><i class="fa fa-check"></i><b>6.8.5</b> Negative Binomial and Hypergeometric: Computing <span class="math inline">\(E(X(X-1))\)</span></a></li>
<li class="chapter" data-level="6.8.6" data-path="moments.html"><a href="moments.html#poisson-exponential-taylor-series"><i class="fa fa-check"></i><b>6.8.6</b> Poisson: Exponential Taylor Series</a></li>
<li class="chapter" data-level="6.8.7" data-path="moments.html"><a href="moments.html#exponential-integration-by-parts"><i class="fa fa-check"></i><b>6.8.7</b> Exponential: Integration By Parts</a></li>
<li class="chapter" data-level="6.8.8" data-path="moments.html"><a href="moments.html#gamma-and-beta-kernel-technique-integration-version"><i class="fa fa-check"></i><b>6.8.8</b> Gamma and Beta: Kernel Technique, Integration Version</a></li>
<li class="chapter" data-level="6.8.9" data-path="moments.html"><a href="moments.html#normal-location-scale-trick-and-polar-integration"><i class="fa fa-check"></i><b>6.8.9</b> Normal: Location-Scale Trick and Polar Integration</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="moments.html"><a href="moments.html#other-moments-for-reference"><i class="fa fa-check"></i><b>6.9</b> Other Moments (for reference)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>7</b> Statistics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistics.html"><a href="statistics.html#sufficient-stats"><i class="fa fa-check"></i><b>7.1</b> Sufficient Statistics</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="statistics.html"><a href="statistics.html#techniques-for-finding-sufficient-statistics"><i class="fa fa-check"></i><b>7.1.1</b> Techniques for Finding Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistics.html"><a href="statistics.html#exp-fam-ss"><i class="fa fa-check"></i><b>7.1.2</b> Exponential Family Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.3" data-path="statistics.html"><a href="statistics.html#a-note-on-distributions-of-sufficient-statistics"><i class="fa fa-check"></i><b>7.1.3</b> A Note on Distributions of Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.4" data-path="statistics.html"><a href="statistics.html#moments-of-the-sufficient-statistic"><i class="fa fa-check"></i><b>7.1.4</b> Moments of the Sufficient Statistic</a></li>
<li class="chapter" data-level="7.1.5" data-path="statistics.html"><a href="statistics.html#table-ss"><i class="fa fa-check"></i><b>7.1.5</b> Table of Sufficient Statistics</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistics.html"><a href="statistics.html#minimal-sufficiency"><i class="fa fa-check"></i><b>7.2</b> Minimal Sufficiency</a></li>
<li class="chapter" data-level="7.3" data-path="statistics.html"><a href="statistics.html#ancillary-stats"><i class="fa fa-check"></i><b>7.3</b> Ancillary Statistics</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="statistics.html"><a href="statistics.html#why-are-we-interested-in-ancillary-statistics"><i class="fa fa-check"></i><b>7.3.1</b> Why are we interested in ancillary statistics?</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="statistics.html"><a href="statistics.html#complete-stats"><i class="fa fa-check"></i><b>7.4</b> Complete Statistics</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="statistics.html"><a href="statistics.html#techniques-for-finding-css"><i class="fa fa-check"></i><b>7.4.1</b> Techniques for Finding CSS</a></li>
<li class="chapter" data-level="7.4.2" data-path="statistics.html"><a href="statistics.html#basus-theorem"><i class="fa fa-check"></i><b>7.4.2</b> Basu’s Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html"><i class="fa fa-check"></i><b>8</b> Point Estimators: Finite Samples</a>
<ul>
<li class="chapter" data-level="8.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#identifiability"><i class="fa fa-check"></i><b>8.1</b> Identifiability</a></li>
<li class="chapter" data-level="8.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-estimators"><i class="fa fa-check"></i><b>8.2</b> Finding estimators</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#method-of-moments"><i class="fa fa-check"></i><b>8.2.1</b> Method of Moments</a></li>
<li class="chapter" data-level="8.2.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>8.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#properties-of-estimators"><i class="fa fa-check"></i><b>8.3</b> Properties of Estimators</a></li>
<li class="chapter" data-level="8.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#uniform-minimum-variance-unbiased-estimators-umvues"><i class="fa fa-check"></i><b>8.4</b> Uniform Minimum Variance Unbiased Estimators (UMVUEs)</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-i-cramér-rao-bound"><i class="fa fa-check"></i><b>8.4.1</b> Finding UMVUEs I: Cramér-Rao Bound</a></li>
<li class="chapter" data-level="8.4.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#rao-blackwell-and-lehmann-scheffé-theorem"><i class="fa fa-check"></i><b>8.4.2</b> Rao-Blackwell and Lehmann-Scheffé Theorem</a></li>
<li class="chapter" data-level="8.4.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-ii-using-the-lehmann-scheffé-theorem"><i class="fa fa-check"></i><b>8.4.3</b> Finding UMVUEs II: Using the Lehmann-Scheffé Theorem</a></li>
<li class="chapter" data-level="8.4.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-iii-lehmann-scheffé-corollary"><i class="fa fa-check"></i><b>8.4.4</b> Finding UMVUEs III: Lehmann-Scheffé Corollary</a></li>
<li class="chapter" data-level="8.4.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#proving-an-umvue-does-not-exist"><i class="fa fa-check"></i><b>8.4.5</b> Proving an UMVUE Does Not Exist</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#inferential-properties-of-exponential-families-distributions"><i class="fa fa-check"></i><b>8.5</b> Inferential Properties of Exponential Families Distributions</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#bernoulli-1"><i class="fa fa-check"></i><b>8.5.1</b> Bernoulli</a></li>
<li class="chapter" data-level="8.5.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#binomial-1"><i class="fa fa-check"></i><b>8.5.2</b> Binomial</a></li>
<li class="chapter" data-level="8.5.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#geometric"><i class="fa fa-check"></i><b>8.5.3</b> Geometric</a></li>
<li class="chapter" data-level="8.5.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#negative-binomial-1"><i class="fa fa-check"></i><b>8.5.4</b> Negative Binomial</a></li>
<li class="chapter" data-level="8.5.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#poisson-1"><i class="fa fa-check"></i><b>8.5.5</b> Poisson</a></li>
<li class="chapter" data-level="8.5.6" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#normal-1"><i class="fa fa-check"></i><b>8.5.6</b> Normal</a></li>
<li class="chapter" data-level="8.5.7" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#exponential-1"><i class="fa fa-check"></i><b>8.5.7</b> Exponential</a></li>
<li class="chapter" data-level="8.5.8" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#gamma-1"><i class="fa fa-check"></i><b>8.5.8</b> Gamma</a></li>
<li class="chapter" data-level="8.5.9" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#pareto-1"><i class="fa fa-check"></i><b>8.5.9</b> Pareto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html"><i class="fa fa-check"></i><b>9</b> Point Estimators: Asymptotics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#consistency"><i class="fa fa-check"></i><b>9.1</b> Consistency</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>9.1.1</b> Technique: Weak Law of Large Numbers</a></li>
<li class="chapter" data-level="9.1.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-direct-proof-via-convergence-in-probability"><i class="fa fa-check"></i><b>9.1.2</b> Technique: Direct Proof via Convergence in Probability</a></li>
<li class="chapter" data-level="9.1.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-continuous-mapping-theorem."><i class="fa fa-check"></i><b>9.1.3</b> Technique: Continuous Mapping Theorem.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-efficiency"><i class="fa fa-check"></i><b>9.2</b> Asymptotic Efficiency</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#central-limit-theorems"><i class="fa fa-check"></i><b>9.2.1</b> Central Limit Theorems</a></li>
<li class="chapter" data-level="9.2.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#the-delta-method"><i class="fa fa-check"></i><b>9.2.2</b> The Delta Method</a></li>
<li class="chapter" data-level="9.2.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#cramer-wold-device"><i class="fa fa-check"></i><b>9.2.3</b> Cramer-Wold Device</a></li>
<li class="chapter" data-level="9.2.4" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-distribution-in-practice"><i class="fa fa-check"></i><b>9.2.4</b> Asymptotic Distribution in Practice</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-properties-of-mles"><i class="fa fa-check"></i><b>9.3</b> Asymptotic Properties of MLEs</a></li>
<li class="chapter" data-level="9.4" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#variance-stabilizing-transformations"><i class="fa fa-check"></i><b>9.4</b> Variance Stabilizing Transformations</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Tests: Finite Samples</a>
<ul>
<li class="chapter" data-level="10.1" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#constructing-a-test"><i class="fa fa-check"></i><b>10.1</b> Constructing a Test</a></li>
<li class="chapter" data-level="10.2" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#lrt"><i class="fa fa-check"></i><b>10.2</b> Likelihood Ratio Tests</a></li>
<li class="chapter" data-level="10.3" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#power"><i class="fa fa-check"></i><b>10.3</b> Power</a></li>
<li class="chapter" data-level="10.4" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#how-to-find-optimal-tests"><i class="fa fa-check"></i><b>10.4</b> How to Find Optimal Tests</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#properties-1"><i class="fa fa-check"></i><b>10.4.1</b> Properties</a></li>
<li class="chapter" data-level="10.4.2" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-simple-hypotheses-the-neyman-pearson-lemma"><i class="fa fa-check"></i><b>10.4.2</b> Optimality for Simple Hypotheses: The Neyman-Pearson Lemma</a></li>
<li class="chapter" data-level="10.4.3" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-one-sided-hypotheses-the-karlin-rubin-theorem"><i class="fa fa-check"></i><b>10.4.3</b> Optimality for One-Sided Hypotheses: The Karlin-Rubin Theorem</a></li>
<li class="chapter" data-level="10.4.4" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-two-sided-hypotheses."><i class="fa fa-check"></i><b>10.4.4</b> Optimality for Two-Sided Hypotheses.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#nuisance-parameters"><i class="fa fa-check"></i><b>10.5</b> Nuisance Parameters</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Tests: Asymptotics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#wald-test"><i class="fa fa-check"></i><b>11.1</b> Wald Test</a></li>
<li class="chapter" data-level="11.2" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#score-test"><i class="fa fa-check"></i><b>11.2</b> Score Test</a></li>
<li class="chapter" data-level="11.3" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>11.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="11.4" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#composite-null-hypotheses"><i class="fa fa-check"></i><b>11.4</b> Composite Null Hypotheses</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#multiple-parameters"><i class="fa fa-check"></i><b>11.4.1</b> Multiple Parameters</a></li>
<li class="chapter" data-level="11.4.2" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#nuisance-parameters-1"><i class="fa fa-check"></i><b>11.4.2</b> Nuisance Parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>12</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="12.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#definition-1"><i class="fa fa-check"></i><b>12.1</b> Definition</a></li>
<li class="chapter" data-level="12.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#test-inversion"><i class="fa fa-check"></i><b>12.2</b> When You’ve Constructed a Hypothesis Test…</a></li>
<li class="chapter" data-level="12.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#when-youve-found-a-pivot-including-asymptotic-normality"><i class="fa fa-check"></i><b>12.3</b> When You’ve Found a Pivot (Including Asymptotic Normality)…</a></li>
<li class="chapter" data-level="12.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#when-all-you-have-is-a-distribution"><i class="fa fa-check"></i><b>12.4</b> When All You Have Is a Distribution…</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="random-processes.html"><a href="random-processes.html"><i class="fa fa-check"></i><b>13</b> Random Processes</a>
<ul>
<li class="chapter" data-level="13.1" data-path="random-processes.html"><a href="random-processes.html#branching-process"><i class="fa fa-check"></i><b>13.1</b> Branching Processes</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="random-processes.html"><a href="random-processes.html#random-variables-1"><i class="fa fa-check"></i><b>13.1.1</b> Random Variables</a></li>
<li class="chapter" data-level="13.1.2" data-path="random-processes.html"><a href="random-processes.html#probability-generating-function"><i class="fa fa-check"></i><b>13.1.2</b> Probability Generating Function</a></li>
<li class="chapter" data-level="13.1.3" data-path="random-processes.html"><a href="random-processes.html#finding-the-pgf-of-a-branching-process"><i class="fa fa-check"></i><b>13.1.3</b> Finding the PGF of a Branching Process</a></li>
<li class="chapter" data-level="13.1.4" data-path="random-processes.html"><a href="random-processes.html#finding-the-probability-of-extinction-criticality-theorem"><i class="fa fa-check"></i><b>13.1.4</b> Finding the Probability of Extinction: Criticality Theorem</a></li>
<li class="chapter" data-level="13.1.5" data-path="random-processes.html"><a href="random-processes.html#example"><i class="fa fa-check"></i><b>13.1.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="random-processes.html"><a href="random-processes.html#poisson-processes"><i class="fa fa-check"></i><b>13.2</b> Poisson Processes</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="random-processes.html"><a href="random-processes.html#memorylessness-of-the-exponential"><i class="fa fa-check"></i><b>13.2.1</b> Memorylessness of the Exponential</a></li>
<li class="chapter" data-level="13.2.2" data-path="random-processes.html"><a href="random-processes.html#count-time-duality"><i class="fa fa-check"></i><b>13.2.2</b> Count-Time Duality</a></li>
<li class="chapter" data-level="13.2.3" data-path="random-processes.html"><a href="random-processes.html#poisson-distribution"><i class="fa fa-check"></i><b>13.2.3</b> Poisson Distribution</a></li>
<li class="chapter" data-level="13.2.4" data-path="random-processes.html"><a href="random-processes.html#exponential-distribution"><i class="fa fa-check"></i><b>13.2.4</b> Exponential Distribution</a></li>
<li class="chapter" data-level="13.2.5" data-path="random-processes.html"><a href="random-processes.html#example-1"><i class="fa fa-check"></i><b>13.2.5</b> Example</a></li>
<li class="chapter" data-level="13.2.6" data-path="random-processes.html"><a href="random-processes.html#merging-and-splitting"><i class="fa fa-check"></i><b>13.2.6</b> Merging and Splitting</a></li>
<li class="chapter" data-level="13.2.7" data-path="random-processes.html"><a href="random-processes.html#thinning"><i class="fa fa-check"></i><b>13.2.7</b> Thinning</a></li>
<li class="chapter" data-level="13.2.8" data-path="random-processes.html"><a href="random-processes.html#restarting"><i class="fa fa-check"></i><b>13.2.8</b> Restarting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Solving Statistical Problems</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-tests-finite-samples" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Chapter 10</span> Hypothesis Tests: Finite Samples<a href="hypothesis-tests-finite-samples.html#hypothesis-tests-finite-samples" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Scientists often formulate scientific hypotheses about the world. Subsequently, statisticians are called upon to determine whether these scientific hypotheses are supported by the data at hand. As statisticians, how do we do this? Here, we prove a simple procedure:</p>
<div id="constructing-a-test" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Constructing a Test<a href="hypothesis-tests-finite-samples.html#constructing-a-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Step 1: Determine Hypotheses.</strong> To start, we first formulate <em>statistical hypotheses</em>, which are mathematical statements about a population parameter. These hypotheses come in pairs: one <strong>null</strong> hypothesis, <span class="math inline">\(H_0\)</span>, and one <strong>alternative</strong> hypothesis, <span class="math inline">\(H_1\)</span>. We write these</p>
<p><span class="math display">\[H_0: \theta \in \Theta_0 \text{  and  } H_1: \theta \in \Theta_1\]</span></p>
<p>Commonly, the sets <span class="math inline">\(\Theta_0\)</span> and <span class="math inline">\(\Theta_1\)</span> are just (in)equality statements. A <em>simple</em> hypothesis is one where <span class="math inline">\(\theta = \theta_0\)</span>, where <span class="math inline">\(\theta_0\)</span> is known to be some fixed value. A <em>composite</em> hypothesis is one where <span class="math inline">\(\theta\)</span> is <em>not</em> known to be a fixed value, but rather is in some range. Examples of composite hypotheses include <span class="math inline">\(\theta &lt; \theta_0\)</span> and <span class="math inline">\(\theta &gt; \theta_0\)</span> (“one-sided” hypotheses), as well as <span class="math inline">\(\theta \neq \theta_0\)</span> (a “two-sided” hypothesis).</p>
<p>In any case, it must be true that <span class="math inline">\(\Theta_0 \cap \Theta_1 = \emptyset\)</span>. This guarantees that only one of the hypotheses can be true. In addition, we assume the sample sample of <span class="math inline">\(\theta\)</span> is <span class="math inline">\(\Theta = \Theta_0 \cup \Theta_1\)</span>.</p>
<p>In a problem, the hypotheses are often given - our job is to construct a test, which is a decision rule telling us which hypotheses we ought to accept.</p>
<p><strong>Step 2: Determine test statistic and its rejection region.</strong> How do we determine which hypothesis is correct? To this, we specify two components:</p>
<ol style="list-style-type: decimal">
<li>The <strong>test statistic</strong>, a function to summarize the data. The test statistic is analogous to an estimator in <a href="point-estimators-finite-samples.html#point-estimators-finite-samples">Chapter 8</a> - it should be selected on the basis of certain properties, which we discuss shortly.</li>
<li>The <strong>rejection region</strong>, a set of values of the test statistic for which the null hypothesis <span class="math inline">\(H_0\)</span> is rejected.</li>
</ol>
<p>The rejection region constitutes our decision rule. For a given test statistic <span class="math inline">\(T\)</span>, it is commonly expressed in two ways:</p>
<ul>
<li>Directly as a set, like so: <span class="math inline">\(\{T &gt; c\}\)</span>, where <span class="math inline">\(c\)</span> is a constant.</li>
<li>As an indicator function: <span class="math inline">\(\phi(T) = I(T &gt; c)\)</span>, which outputs 1 if we reject the null <span class="math inline">\(H_0\)</span> and 0 if we reject the alternative <span class="math inline">\(H_1\)</span>.</li>
</ul>
<p><strong>Step 3: Compute the rejection region for a given <span class="math inline">\(\alpha\)</span>.</strong> For a rejection region <span class="math inline">\(\{T &gt; c\}\)</span>, the goal is to set <span class="math inline">\(c\)</span> such that we control <span class="math inline">\(\alpha\)</span>, the maximum probability of wrongly rejecting <span class="math inline">\(H_0\)</span>. This is discussed in the <a href="hypothesis-tests-finite-samples.html#power">Power</a> section below.</p>
<p>Accomplishing all three of these steps yields a valid hypothesis test! Now let’s delve more deeply into how exactly each step is accomplished.</p>
</div>
<div id="lrt" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Likelihood Ratio Tests<a href="hypothesis-tests-finite-samples.html#lrt" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Firstly, how do we find a valid test statistic? In some cases, the test statistic may be given. In others, we can use the <strong>likelihood ratio test</strong> (LRT), which is analogous to the MLE for point estimators. The likelihood ratio test statistic for <span class="math inline">\(H_0: \theta \in \Theta_0\)</span> is</p>
<p><span class="math display">\[\lambda(x) = \frac{\sup_{\theta\in\Theta_0}\mathcal{L}(\theta|x)}{\sup_{\theta\in\Theta}\mathcal{L}(\theta|x)}\]</span>
aka, the ratio of the likelihood under the null to the full likelihood. Then, the likelihood ratio test rejection region is</p>
<p><span class="math display">\[R = \{\lambda(x) \leq c\}\]</span>
where <span class="math inline">\(0 &lt; c &lt; 1\)</span>.</p>
<p>The easiest way to compute <span class="math inline">\(\lambda(x)\)</span> is to do the following:</p>
<ol style="list-style-type: decimal">
<li>Find the MLE of <span class="math inline">\(\theta\)</span>, call it <span class="math inline">\(\hat{\theta}\)</span>.</li>
<li>Find the “restricted MLE”, such that <span class="math inline">\(\theta\in\Theta_0\)</span>, call it <span class="math inline">\(\hat{\theta}_0\)</span>.</li>
<li>Plug the MLE and restricted MLE into the likelihood, effectively computing the ratio</li>
</ol>
<p><span class="math display">\[\lambda(x) = \frac{\mathcal{L}(\hat{\theta}_0|x)}{\mathcal{L}(\hat{\theta}|x)}\]</span>
This yields the LRT. Another potentially simpler way to find the LRT is to use a sufficient statistic <span class="math inline">\(T(X)\)</span>. By the <a href="#factorization-theorem">Factorization Theorem</a>, <span class="math inline">\(\mathcal{L}(\theta|x) = f_X(x|\theta) = f_{T(X)}(t|\theta)\cdot h(x)\)</span>. In this case,</p>
<p><span class="math display">\[\lambda(x) = \frac{\sup_{\theta\in\Theta_0}\mathcal{L}(\theta|x)}{\sup_{\theta\in\Theta}\mathcal{L}(\theta|x)} = \frac{\sup_{\theta\in\Theta_0}f_{T(X)}(t|\theta)\cdot h(x)}{\sup_{\theta\in\Theta}f_{T(X)}(t|\theta)\cdot h(x)} = \frac{\sup_{\theta\in\Theta_0}\mathcal{L}(\theta|t)}{\sup_{\theta\in\Theta}\mathcal{L}(\theta|t)}\]</span></p>
<p>Therefore, if we know the distribution of a sufficient statistic <span class="math inline">\(T\)</span>, we can construct an LRT based on <span class="math inline">\(T\)</span> instead of <span class="math inline">\(X\)</span>. This can be very useful if <span class="math inline">\(X\)</span> is known to be an exponential family or otherwise admits an easy-to-find sufficient statistic.</p>
</div>
<div id="power" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Power<a href="hypothesis-tests-finite-samples.html#power" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Once we have the LRT or some other statistic, we need to find <span class="math inline">\(c\)</span> in the rejection region <span class="math inline">\(R = \{T(X) \leq c\}\)</span> (or <span class="math inline">\(\{T(X) \geq c\}\)</span>, depending on the hypothesis). This is done by controlling error rates. There are two types of error:</p>
<ul>
<li><strong>Type I:</strong> When <span class="math inline">\(\theta \in \Theta_0\)</span>, but the test incorrectly rejects <span class="math inline">\(H_0\)</span>.</li>
<li><strong>Type II:</strong> When <span class="math inline">\(\theta \in \Theta_1\)</span>, but the test incorrectly rejects <span class="math inline">\(H_1\)</span> (or equivalently, accepts <span class="math inline">\(H_0\)</span>)</li>
</ul>
<p>Here is a nifty table summarizing the errors:</p>
<table>
<thead>
<tr class="header">
<th align="center">Truth</th>
<th align="center">Accept <span class="math inline">\(H_0\)</span></th>
<th align="center">Reject <span class="math inline">\(H_0\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(H_0\)</span></td>
<td align="center">✔️</td>
<td align="center">Type I</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(H_1\)</span></td>
<td align="center">Type II</td>
<td align="center">✔️</td>
</tr>
</tbody>
</table>
<p>If you’re familiar with the children’s fable “<a href="https://en.wikipedia.org/wiki/The_Boy_Who_Cried_Wolf">The Boy Who Cried Wolf</a>,” one way to remember which error is which is via the mnemonic:</p>
<p>“When the boy cried wolf, the villagers committed a Type I and a Type II error, in that order.”</p>
<p>Back to statistics! These two error rates are summarized by the test’s <strong>power</strong>. The <strong>power function</strong> of a test is</p>
<p><span class="math display">\[\beta(\theta) = P(T \in R | \theta) = \begin{cases}P(\text{Type I error}) &amp; \text{if } \theta \in \Theta_0\\ 1 - P(\text{Type II error}) &amp; \text{if } \theta \in \Theta_1\end{cases}\]</span></p>
<p>When choosing <span class="math inline">\(c\)</span> in the hypothesis test, we want to control these errors. The most common way of doing so is by specifying the <strong>size</strong>, <span class="math inline">\(\alpha\)</span>, of the test, defined as:</p>
<p><span class="math display">\[\alpha = \sup_{\theta \in \Theta_0}\beta(\theta)\]</span>
Hence, the size measures the maximum type I error that we may commit when <span class="math inline">\(H_0\)</span> is true. When <span class="math inline">\(X\)</span> is discrete, sometimes consider the <strong>level</strong> , which is defined analogously as</p>
<p><span class="math display">\[\alpha \leq \sup_{\theta \in \Theta_0}\beta(\theta)\]</span>
Level <span class="math inline">\(\alpha\)</span> is essentially the same as size <span class="math inline">\(\alpha\)</span>, but conservative. It accounts for the fact that when <span class="math inline">\(X\)</span> is discrete, we may not be able to set <span class="math inline">\(c\)</span> to achieve an exact <span class="math inline">\(\alpha\)</span>.</p>
<p>We may also be asked to consider the <strong>maximum Type II</strong> error, which is defined analogously assuming <span class="math inline">\(H_1\)</span> is true instead as</p>
<p><span class="math display">\[\alpha = \sup_{\theta \in \Theta_1}\beta(\theta)\]</span>
How might we do this in practice? Let’s see an example.</p>
<div class="example">
<p><span id="exm:unlabeled-div-126" class="example"><strong>Example 10.1  (Finding an LRT and its Power Function) </strong></span>FORTHCOMING</p>
</div>
</div>
<div id="how-to-find-optimal-tests" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> How to Find Optimal Tests<a href="hypothesis-tests-finite-samples.html#how-to-find-optimal-tests" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In <a href="point-estimators-finite-samples.html#point-estimators-finite-samples">Chapter 8</a>, we discussed how construction of a point estimator must consider two properties - unbiasedness and minimum variance - and how the ultimate goal is to construct an UMVUE. Hypothesis tests have analogous properties. In this section, we define these properties and show how to achieve them.</p>
<div id="properties-1" class="section level3 hasAnchor" number="10.4.1">
<h3><span class="header-section-number">10.4.1</span> Properties<a href="hypothesis-tests-finite-samples.html#properties-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Unbiased</strong>: A test is said to be “unbiased” if, for all <span class="math inline">\(\theta_1 \in \Theta_1\)</span> and <span class="math inline">\(\theta_0 \in \Theta_0\)</span>,</p>
<p><span class="math display">\[\beta(\theta_1) &gt; \beta(\theta_0)\]</span>
or, equivalently,</p>
<p><span class="math display">\[\inf_{\theta\in\Theta_1} \beta(\theta) \geq \sup_{\theta\in\Theta_0}\beta(\theta)\]</span>
Intuitively, this means that an unbiased test, even in the worst-case scenario, has a higher probability of rejecting <span class="math inline">\(H_0\)</span> when it is actually false than rejecting <span class="math inline">\(H_0\)</span> when it is true. Unbiasedness can be proven directly from the power function.</p>
<p><strong>Most Powerful</strong>
Consider the set <span class="math inline">\(C\)</span> of all level <span class="math inline">\(\alpha\)</span> tests for a given <span class="math inline">\(\theta_1 \in \Theta_1\)</span>. Among these tests, <span class="math inline">\(W\)</span> is considered the “most powerful” (MP) if</p>
<p><span class="math display">\[\beta_W(\theta_1) \geq \beta_{W^*}(\theta_1)\]</span>
for all <span class="math inline">\(W^* \in C\)</span>.</p>
<p>Intuitively, a “most powerful” test has the highest probability of correctly rejecting <span class="math inline">\(H_0\)</span> when <span class="math inline">\(H_0\)</span> is actually false (considering the “worst-case scenario” across all other possible tests). An MP test is defined for a specific <span class="math inline">\(\theta_1\)</span>.</p>
<p><strong>Uniformly Most Powerful</strong>
Usually, we care about a test’s performance across <em>all</em> <span class="math inline">\(\theta_1 \in \Theta_1\)</span>. A test is considered “uniformly most powerful” (UMP) if it is the most powerful for all <span class="math inline">\(\theta_1 \in \Theta_1\)</span>.</p>
<p>In other words, for a class <span class="math inline">\(C\)</span> of level <span class="math inline">\(\alpha\)</span> tests, if <span class="math inline">\(\beta_W(\theta) \geq \beta_{W^*}(\theta)\)</span> for all <span class="math inline">\(\theta \in \Theta_1\)</span> and <span class="math inline">\(W^* \in C\)</span>, then <span class="math inline">\(W\)</span> is the UMP test.</p>
<p><strong>Locally Most Powerful</strong></p>
<p>Sometimes it may not be possible to find a UMP test. In this case, we can consider Locally Most Powerful (LMP) tests.</p>
<p>FORTHCOMING</p>
</div>
<div id="optimality-for-simple-hypotheses-the-neyman-pearson-lemma" class="section level3 hasAnchor" number="10.4.2">
<h3><span class="header-section-number">10.4.2</span> Optimality for Simple Hypotheses: The Neyman-Pearson Lemma<a href="hypothesis-tests-finite-samples.html#optimality-for-simple-hypotheses-the-neyman-pearson-lemma" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Neyman-Pearson Lemma defines a UMP test when both the null and alternative hypotheses are simple.</p>
<div class="lemma">
<p><span id="lem:unlabeled-div-127" class="lemma"><strong>Lemma 10.1  (Neyman-Pearson Lemma) </strong></span>Suppose we have a set of simple hypotheses:</p>
<p><span class="math display">\[H_0: \theta = \theta_0, H_1: \theta = \theta_1\]</span></p>
<p>For <span class="math inline">\(X \sim f(x|\theta)\)</span>, let the rejection region be</p>
<p><span class="math display">\[R =  \Big\{\frac{f(x|\theta_1)}{f(x|\theta_0)} &gt; k\Big\}\]</span>
with <span class="math inline">\(k \geq 0\)</span>. Then,</p>
<ol style="list-style-type: decimal">
<li>The test with rejection region <span class="math inline">\(R\)</span> is UMP level <span class="math inline">\(\alpha = P(X \in R | \theta = \theta_0)\)</span> (Sufficiency)</li>
<li>Every UMP level <span class="math inline">\(\alpha\)</span> test satisfies the above and is size <span class="math inline">\(\alpha\)</span> (except on a set with probability 0) (Necessary).</li>
</ol>
</div>
<p>In addition, a corollary to the Neyman-Pearson lemma states that we can also construct such a test based on a sufficient statistic, using the Factorization theorem on both the numerator and the denominator to cancel out the extraneous <span class="math inline">\(h(x)\)</span>. Then,</p>
<p><span class="math display">\[R =  \Big\{\frac{f(t|\theta_1)}{f(t|\theta_0)} &gt; k\Big\}\]</span>
is an UMP level <span class="math inline">\(\alpha\)</span> test.</p>
</div>
<div id="optimality-for-one-sided-hypotheses-the-karlin-rubin-theorem" class="section level3 hasAnchor" number="10.4.3">
<h3><span class="header-section-number">10.4.3</span> Optimality for One-Sided Hypotheses: The Karlin-Rubin Theorem<a href="hypothesis-tests-finite-samples.html#optimality-for-one-sided-hypotheses-the-karlin-rubin-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>It is more common to see one-sided tests. The Karlin-Rubin Theorem defines a UMP test when both the null and alternative hypotheses are one-sided composite.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-128" class="theorem"><strong>Theorem 10.1  (Karlin-Rubin Theorem) </strong></span>Suppose <span class="math inline">\(H_0: \theta \leq \theta_0\)</span> and <span class="math inline">\(H_1: \theta &gt; \theta_0\)</span>. Then, if…</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(T\)</span> is a sufficient statistic</li>
<li><span class="math inline">\(T\)</span> has a monotone likelihood ratio</li>
<li><span class="math inline">\(P(T &gt; t_0 |\theta_0) = \alpha\)</span></li>
</ol>
<p>then the test with rejection region <span class="math inline">\(R = \Big\{T &gt; t_0 \Big\}\)</span> is the UMP level <span class="math inline">\(\alpha\)</span> test of <span class="math inline">\(H_0\)</span> versus <span class="math inline">\(H_1\)</span>.</p>
</div>
<p>This theorem follows from the Neyman-Pearson corollary. As a result, finding an UMP test typically amounts to identifying a sufficient statistic, and proving that it has a monotone likelihood ratio.</p>
<div class="definition">
<p><span id="def:unlabeled-div-129" class="definition"><strong>Definition 10.1  (Monotone Likelihood Ratio) </strong></span>A family <span class="math inline">\(f(t|\theta)\)</span> has a monotone likelihood ratio if, for all <span class="math inline">\(\theta_1, \theta_2 \in \Theta\)</span> such that <span class="math inline">\(\theta_1 &lt; \theta_2\)</span>,</p>
<p><span class="math display">\[\frac{f(t|\theta_2)}{f(t|\theta_1)}\]</span></p>
<p>is a monotone nondecreasing function of <span class="math inline">\(t\)</span> when either <span class="math inline">\(f(t|\theta_1) &gt;0\)</span> or <span class="math inline">\(f(t|\theta_0) &gt;0\)</span></p>
</div>
<p>If instead <span class="math inline">\(f(t|\theta)\)</span> is nonincreasing, use <span class="math inline">\(-T\)</span> instead of <span class="math inline">\(T\)</span> in the Karlin-Rubin theorem to obtain a statistic with a monotone likelihood ratio.</p>
<p>Also, note that all 1-parameter exponential families have a monotone likelihood ratio - a convenient property simplifying proofs.</p>
</div>
<div id="optimality-for-two-sided-hypotheses." class="section level3 hasAnchor" number="10.4.4">
<h3><span class="header-section-number">10.4.4</span> Optimality for Two-Sided Hypotheses.<a href="hypothesis-tests-finite-samples.html#optimality-for-two-sided-hypotheses." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In this section we will show how to construct a UMP test for a two-sided composite hypothesis.</p>
<p>Sike! This is actually impossible. No UMP test exists for <span class="math inline">\(H_0: \theta = \theta_0, H_1: \theta \neq \theta_0\)</span>. For such a test to be UMP, it must be UMP for both <span class="math inline">\(\theta &lt; \theta_0\)</span> and for <span class="math inline">\(\theta &gt; \theta_0\)</span>, which creates a contradiction.</p>
</div>
</div>
<div id="nuisance-parameters" class="section level2 hasAnchor" number="10.5">
<h2><span class="header-section-number">10.5</span> Nuisance Parameters<a href="hypothesis-tests-finite-samples.html#nuisance-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>FORTHCOMING</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="point-estimators-asymptotics.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis-tests-asymptotics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/10-hypothesis-tests-finite-samples.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Solving-Statistical-Problems.pdf", "Solving-Statistical-Problems.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
