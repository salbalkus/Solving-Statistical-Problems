<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Random Processes | Solving Statistical Problems</title>
  <meta name="description" content="Chapter 13 Random Processes | Solving Statistical Problems" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Random Processes | Solving Statistical Problems" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 13 Random Processes | Solving Statistical Problems" />
  <meta name="github-repo" content="salbalkus/Solving-Statistical-Problems" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Random Processes | Solving Statistical Problems" />
  
  <meta name="twitter:description" content="Chapter 13 Random Processes | Solving Statistical Problems" />
  

<meta name="author" content="Salvador Balkus, Kimberly Greco, and Mónica Robles Fontán" />


<meta name="date" content="2023-08-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="confidence-intervals.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Solving Statistical Problems</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="math-tricks.html"><a href="math-tricks.html"><i class="fa fa-check"></i><b>2</b> Math Tricks</a>
<ul>
<li class="chapter" data-level="2.1" data-path="math-tricks.html"><a href="math-tricks.html#combinatorics"><i class="fa fa-check"></i><b>2.1</b> Combinatorics</a></li>
<li class="chapter" data-level="2.2" data-path="math-tricks.html"><a href="math-tricks.html#binomial-and-multinomial-theorems"><i class="fa fa-check"></i><b>2.2</b> Binomial and Multinomial Theorems</a></li>
<li class="chapter" data-level="2.3" data-path="math-tricks.html"><a href="math-tricks.html#geometric-series"><i class="fa fa-check"></i><b>2.3</b> Geometric Series</a></li>
<li class="chapter" data-level="2.4" data-path="math-tricks.html"><a href="math-tricks.html#exponential-taylor"><i class="fa fa-check"></i><b>2.4</b> Taylor Series for Exponential Function</a></li>
<li class="chapter" data-level="2.5" data-path="math-tricks.html"><a href="math-tricks.html#taylors-formula"><i class="fa fa-check"></i><b>2.5</b> Taylor’s Formula</a></li>
<li class="chapter" data-level="2.6" data-path="math-tricks.html"><a href="math-tricks.html#exponential-limit"><i class="fa fa-check"></i><b>2.6</b> Exponential Limit</a></li>
<li class="chapter" data-level="2.7" data-path="math-tricks.html"><a href="math-tricks.html#ibp"><i class="fa fa-check"></i><b>2.7</b> Integration by Parts</a></li>
<li class="chapter" data-level="2.8" data-path="math-tricks.html"><a href="math-tricks.html#leibniz-rule"><i class="fa fa-check"></i><b>2.8</b> Leibniz’s Rule</a></li>
<li class="chapter" data-level="2.9" data-path="math-tricks.html"><a href="math-tricks.html#fubinis-theorem"><i class="fa fa-check"></i><b>2.9</b> Fubini’s Theorem</a></li>
<li class="chapter" data-level="2.10" data-path="math-tricks.html"><a href="math-tricks.html#gamma-function"><i class="fa fa-check"></i><b>2.10</b> Gamma Function</a></li>
<li class="chapter" data-level="2.11" data-path="math-tricks.html"><a href="math-tricks.html#triangle-inequality"><i class="fa fa-check"></i><b>2.11</b> Triangle Inequality</a></li>
<li class="chapter" data-level="2.12" data-path="math-tricks.html"><a href="math-tricks.html#constrained-optimization"><i class="fa fa-check"></i><b>2.12</b> Constrained Optimization</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#basic-axioms"><i class="fa fa-check"></i><b>3.1</b> Basic Axioms</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#basic-probability-solving-techniques"><i class="fa fa-check"></i><b>3.2</b> Basic Probability Solving Techniques</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#disjointify"><i class="fa fa-check"></i><b>3.2.1</b> Disjointification</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#demorgan"><i class="fa fa-check"></i><b>3.2.2</b> DeMorgan’s Laws</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#proving-inequalities-subsetting"><i class="fa fa-check"></i><b>3.2.3</b> Proving Inequalities: Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>3.3</b> Conditional Probability</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="probability.html"><a href="probability.html#conditional-probability-in-practice"><i class="fa fa-check"></i><b>3.3.1</b> Conditional Probability in Practice</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#random-variables"><i class="fa fa-check"></i><b>3.4</b> Random Variables</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability.html"><a href="probability.html#definition"><i class="fa fa-check"></i><b>3.4.1</b> Definition</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability.html"><a href="probability.html#functions-describing-the-distribution"><i class="fa fa-check"></i><b>3.4.2</b> Functions Describing the Distribution</a></li>
<li class="chapter" data-level="3.4.3" data-path="probability.html"><a href="probability.html#direct-manipulation"><i class="fa fa-check"></i><b>3.4.3</b> Technique: Direct Probability Manipulation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>3.5</b> Independence</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#order-statistics"><i class="fa fa-check"></i><b>3.6</b> Order Statistics</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#convergence"><i class="fa fa-check"></i><b>3.7</b> Convergence</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="probability.html"><a href="probability.html#borel-cantelli-lemmas"><i class="fa fa-check"></i><b>3.7.1</b> Borel-Cantelli Lemmas</a></li>
<li class="chapter" data-level="3.7.2" data-path="probability.html"><a href="probability.html#convergence-in-probability"><i class="fa fa-check"></i><b>3.7.2</b> Convergence in Probability</a></li>
<li class="chapter" data-level="3.7.3" data-path="probability.html"><a href="probability.html#convergence-in-distribution"><i class="fa fa-check"></i><b>3.7.3</b> Convergence in Distribution</a></li>
<li class="chapter" data-level="3.7.4" data-path="probability.html"><a href="probability.html#important-theorems"><i class="fa fa-check"></i><b>3.7.4</b> Important Theorems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="known-distributions.html"><a href="known-distributions.html"><i class="fa fa-check"></i><b>4</b> Known Distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="known-distributions.html"><a href="known-distributions.html#families-of-distributions"><i class="fa fa-check"></i><b>4.1</b> Families of Distributions</a></li>
<li class="chapter" data-level="4.2" data-path="known-distributions.html"><a href="known-distributions.html#location-scale"><i class="fa fa-check"></i><b>4.2</b> Location and Scale Families</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="known-distributions.html"><a href="known-distributions.html#location-families"><i class="fa fa-check"></i><b>4.2.1</b> Location Families</a></li>
<li class="chapter" data-level="4.2.2" data-path="known-distributions.html"><a href="known-distributions.html#scale-families"><i class="fa fa-check"></i><b>4.2.2</b> Scale Families</a></li>
<li class="chapter" data-level="4.2.3" data-path="known-distributions.html"><a href="known-distributions.html#properties-of-location-scale-families"><i class="fa fa-check"></i><b>4.2.3</b> Properties of Location-Scale Families</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="known-distributions.html"><a href="known-distributions.html#exponential-family"><i class="fa fa-check"></i><b>4.3</b> Exponential Families</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="known-distributions.html"><a href="known-distributions.html#properties"><i class="fa fa-check"></i><b>4.3.1</b> Properties</a></li>
<li class="chapter" data-level="4.3.2" data-path="known-distributions.html"><a href="known-distributions.html#natural-exponential-family"><i class="fa fa-check"></i><b>4.3.2</b> Natural Exponential Families</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="known-distributions.html"><a href="known-distributions.html#known-univariate-exponential-families"><i class="fa fa-check"></i><b>4.4</b> Known Univariate Exponential Families</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="known-distributions.html"><a href="known-distributions.html#bernoulli"><i class="fa fa-check"></i><b>4.4.1</b> Bernoulli</a></li>
<li class="chapter" data-level="4.4.2" data-path="known-distributions.html"><a href="known-distributions.html#binomial"><i class="fa fa-check"></i><b>4.4.2</b> Binomial</a></li>
<li class="chapter" data-level="4.4.3" data-path="known-distributions.html"><a href="known-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>4.4.3</b> Geometric</a></li>
<li class="chapter" data-level="4.4.4" data-path="known-distributions.html"><a href="known-distributions.html#negative-binomial"><i class="fa fa-check"></i><b>4.4.4</b> Negative Binomial</a></li>
<li class="chapter" data-level="4.4.5" data-path="known-distributions.html"><a href="known-distributions.html#poisson"><i class="fa fa-check"></i><b>4.4.5</b> Poisson</a></li>
<li class="chapter" data-level="4.4.6" data-path="known-distributions.html"><a href="known-distributions.html#normal"><i class="fa fa-check"></i><b>4.4.6</b> Normal</a></li>
<li class="chapter" data-level="4.4.7" data-path="known-distributions.html"><a href="known-distributions.html#exponential"><i class="fa fa-check"></i><b>4.4.7</b> Exponential</a></li>
<li class="chapter" data-level="4.4.8" data-path="known-distributions.html"><a href="known-distributions.html#gamma"><i class="fa fa-check"></i><b>4.4.8</b> Gamma</a></li>
<li class="chapter" data-level="4.4.9" data-path="known-distributions.html"><a href="known-distributions.html#beta"><i class="fa fa-check"></i><b>4.4.9</b> Beta</a></li>
<li class="chapter" data-level="4.4.10" data-path="known-distributions.html"><a href="known-distributions.html#chi-squared"><i class="fa fa-check"></i><b>4.4.10</b> Chi-squared</a></li>
<li class="chapter" data-level="4.4.11" data-path="known-distributions.html"><a href="known-distributions.html#weibull"><i class="fa fa-check"></i><b>4.4.11</b> Weibull</a></li>
<li class="chapter" data-level="4.4.12" data-path="known-distributions.html"><a href="known-distributions.html#pareto"><i class="fa fa-check"></i><b>4.4.12</b> Pareto</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="known-distributions.html"><a href="known-distributions.html#non-exponential-families"><i class="fa fa-check"></i><b>4.5</b> Non-exponential families</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="known-distributions.html"><a href="known-distributions.html#uniform"><i class="fa fa-check"></i><b>4.5.1</b> Uniform</a></li>
<li class="chapter" data-level="4.5.2" data-path="known-distributions.html"><a href="known-distributions.html#cauchy"><i class="fa fa-check"></i><b>4.5.2</b> Cauchy</a></li>
<li class="chapter" data-level="4.5.3" data-path="known-distributions.html"><a href="known-distributions.html#studentst"><i class="fa fa-check"></i><b>4.5.3</b> t-distribution</a></li>
<li class="chapter" data-level="4.5.4" data-path="known-distributions.html"><a href="known-distributions.html#f-distribution"><i class="fa fa-check"></i><b>4.5.4</b> F-distribution</a></li>
<li class="chapter" data-level="4.5.5" data-path="known-distributions.html"><a href="known-distributions.html#hypergeometric"><i class="fa fa-check"></i><b>4.5.5</b> Hypergeometric</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="known-distributions.html"><a href="known-distributions.html#multivariate-distributions"><i class="fa fa-check"></i><b>4.6</b> Multivariate Distributions</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="known-distributions.html"><a href="known-distributions.html#bivariate-normal"><i class="fa fa-check"></i><b>4.6.1</b> Bivariate Normal</a></li>
<li class="chapter" data-level="4.6.2" data-path="known-distributions.html"><a href="known-distributions.html#multivariate-normal"><i class="fa fa-check"></i><b>4.6.2</b> Multivariate Normal</a></li>
<li class="chapter" data-level="4.6.3" data-path="known-distributions.html"><a href="known-distributions.html#multinomial"><i class="fa fa-check"></i><b>4.6.3</b> Multinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="known-distributions.html"><a href="known-distributions.html#medians-and-other-functionals-of-a-distribution"><i class="fa fa-check"></i><b>4.7</b> Medians and Other Functionals of a Distribution</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="new-distributions.html"><a href="new-distributions.html"><i class="fa fa-check"></i><b>5</b> New Distributions</a>
<ul>
<li class="chapter" data-level="5.1" data-path="new-distributions.html"><a href="new-distributions.html#transformations"><i class="fa fa-check"></i><b>5.1</b> Transformations</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="new-distributions.html"><a href="new-distributions.html#theorems"><i class="fa fa-check"></i><b>5.1.1</b> Theorems</a></li>
<li class="chapter" data-level="5.1.2" data-path="new-distributions.html"><a href="new-distributions.html#practical-strategy"><i class="fa fa-check"></i><b>5.1.2</b> Practical Strategy</a></li>
<li class="chapter" data-level="5.1.3" data-path="new-distributions.html"><a href="new-distributions.html#proving-independence-from-a-joint-transformation"><i class="fa fa-check"></i><b>5.1.3</b> Proving Independence From a Joint Transformation</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="new-distributions.html"><a href="new-distributions.html#computing-joint-probabilities"><i class="fa fa-check"></i><b>5.2</b> Computing Joint Probabilities</a></li>
<li class="chapter" data-level="5.3" data-path="new-distributions.html"><a href="new-distributions.html#probability-integral-transform"><i class="fa fa-check"></i><b>5.3</b> Probability Integral Transform</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="new-distributions.html"><a href="new-distributions.html#hierarchical-models-iterated-moments"><i class="fa fa-check"></i><b>5.3.1</b> Hierarchical Models (Iterated Moments)</a></li>
<li class="chapter" data-level="5.3.2" data-path="new-distributions.html"><a href="new-distributions.html#convolutions"><i class="fa fa-check"></i><b>5.3.2</b> Convolutions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="moments.html"><a href="moments.html"><i class="fa fa-check"></i><b>6</b> Moments</a>
<ul>
<li class="chapter" data-level="6.1" data-path="moments.html"><a href="moments.html#basic-definitions"><i class="fa fa-check"></i><b>6.1</b> Basic Definitions</a></li>
<li class="chapter" data-level="6.2" data-path="moments.html"><a href="moments.html#expected-value"><i class="fa fa-check"></i><b>6.2</b> <span class="math inline">\(E(X)\)</span> Properties</a></li>
<li class="chapter" data-level="6.3" data-path="moments.html"><a href="moments.html#varx-properties"><i class="fa fa-check"></i><b>6.3</b> <span class="math inline">\(Var(X)\)</span> Properties</a></li>
<li class="chapter" data-level="6.4" data-path="moments.html"><a href="moments.html#covariance-and-correlation"><i class="fa fa-check"></i><b>6.4</b> Covariance and Correlation</a></li>
<li class="chapter" data-level="6.5" data-path="moments.html"><a href="moments.html#conditional-expectation"><i class="fa fa-check"></i><b>6.5</b> Conditional Expectation</a></li>
<li class="chapter" data-level="6.6" data-path="moments.html"><a href="moments.html#mgf"><i class="fa fa-check"></i><b>6.6</b> Moment Generating Functions</a></li>
<li class="chapter" data-level="6.7" data-path="moments.html"><a href="moments.html#moment-bounds"><i class="fa fa-check"></i><b>6.7</b> Moment Inequalities</a></li>
<li class="chapter" data-level="6.8" data-path="moments.html"><a href="moments.html#techniques-for-deriving-moments"><i class="fa fa-check"></i><b>6.8</b> Techniques for Deriving Moments</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="moments.html"><a href="moments.html#bernoulli-direct-summation"><i class="fa fa-check"></i><b>6.8.1</b> Bernoulli: Direct Summation</a></li>
<li class="chapter" data-level="6.8.2" data-path="moments.html"><a href="moments.html#uniform-direct-integration"><i class="fa fa-check"></i><b>6.8.2</b> Uniform: Direct Integration</a></li>
<li class="chapter" data-level="6.8.3" data-path="moments.html"><a href="moments.html#geometric-series-convergence"><i class="fa fa-check"></i><b>6.8.3</b> Geometric: Series Convergence</a></li>
<li class="chapter" data-level="6.8.4" data-path="moments.html"><a href="moments.html#binomial-kernel-technique-series-version"><i class="fa fa-check"></i><b>6.8.4</b> Binomial: Kernel Technique, Series Version</a></li>
<li class="chapter" data-level="6.8.5" data-path="moments.html"><a href="moments.html#negative-binomial-and-hypergeometric-computing-exx-1"><i class="fa fa-check"></i><b>6.8.5</b> Negative Binomial and Hypergeometric: Computing <span class="math inline">\(E(X(X-1))\)</span></a></li>
<li class="chapter" data-level="6.8.6" data-path="moments.html"><a href="moments.html#poisson-exponential-taylor-series"><i class="fa fa-check"></i><b>6.8.6</b> Poisson: Exponential Taylor Series</a></li>
<li class="chapter" data-level="6.8.7" data-path="moments.html"><a href="moments.html#exponential-integration-by-parts"><i class="fa fa-check"></i><b>6.8.7</b> Exponential: Integration By Parts</a></li>
<li class="chapter" data-level="6.8.8" data-path="moments.html"><a href="moments.html#gamma-and-beta-kernel-technique-integration-version"><i class="fa fa-check"></i><b>6.8.8</b> Gamma and Beta: Kernel Technique, Integration Version</a></li>
<li class="chapter" data-level="6.8.9" data-path="moments.html"><a href="moments.html#normal-location-scale-trick-and-polar-integration"><i class="fa fa-check"></i><b>6.8.9</b> Normal: Location-Scale Trick and Polar Integration</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="moments.html"><a href="moments.html#other-moments-for-reference"><i class="fa fa-check"></i><b>6.9</b> Other Moments (for reference)</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>7</b> Statistics</a>
<ul>
<li class="chapter" data-level="7.1" data-path="statistics.html"><a href="statistics.html#sufficient-stats"><i class="fa fa-check"></i><b>7.1</b> Sufficient Statistics</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="statistics.html"><a href="statistics.html#techniques-for-finding-sufficient-statistics"><i class="fa fa-check"></i><b>7.1.1</b> Techniques for Finding Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistics.html"><a href="statistics.html#exp-fam-ss"><i class="fa fa-check"></i><b>7.1.2</b> Exponential Family Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.3" data-path="statistics.html"><a href="statistics.html#a-note-on-distributions-of-sufficient-statistics"><i class="fa fa-check"></i><b>7.1.3</b> A Note on Distributions of Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.4" data-path="statistics.html"><a href="statistics.html#moments-of-the-sufficient-statistic"><i class="fa fa-check"></i><b>7.1.4</b> Moments of the Sufficient Statistic</a></li>
<li class="chapter" data-level="7.1.5" data-path="statistics.html"><a href="statistics.html#table-ss"><i class="fa fa-check"></i><b>7.1.5</b> Table of Sufficient Statistics</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistics.html"><a href="statistics.html#minimal-sufficiency"><i class="fa fa-check"></i><b>7.2</b> Minimal Sufficiency</a></li>
<li class="chapter" data-level="7.3" data-path="statistics.html"><a href="statistics.html#ancillary-stats"><i class="fa fa-check"></i><b>7.3</b> Ancillary Statistics</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="statistics.html"><a href="statistics.html#why-are-we-interested-in-ancillary-statistics"><i class="fa fa-check"></i><b>7.3.1</b> Why are we interested in ancillary statistics?</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="statistics.html"><a href="statistics.html#complete-stats"><i class="fa fa-check"></i><b>7.4</b> Complete Statistics</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="statistics.html"><a href="statistics.html#techniques-for-finding-css"><i class="fa fa-check"></i><b>7.4.1</b> Techniques for Finding CSS</a></li>
<li class="chapter" data-level="7.4.2" data-path="statistics.html"><a href="statistics.html#basus-theorem"><i class="fa fa-check"></i><b>7.4.2</b> Basu’s Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html"><i class="fa fa-check"></i><b>8</b> Point Estimators: Finite Samples</a>
<ul>
<li class="chapter" data-level="8.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#identifiability"><i class="fa fa-check"></i><b>8.1</b> Identifiability</a></li>
<li class="chapter" data-level="8.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-estimators"><i class="fa fa-check"></i><b>8.2</b> Finding estimators</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#method-of-moments"><i class="fa fa-check"></i><b>8.2.1</b> Method of Moments</a></li>
<li class="chapter" data-level="8.2.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>8.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#properties-of-estimators"><i class="fa fa-check"></i><b>8.3</b> Properties of Estimators</a></li>
<li class="chapter" data-level="8.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#uniform-minimum-variance-unbiased-estimators-umvues"><i class="fa fa-check"></i><b>8.4</b> Uniform Minimum Variance Unbiased Estimators (UMVUEs)</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-i-cramér-rao-bound"><i class="fa fa-check"></i><b>8.4.1</b> Finding UMVUEs I: Cramér-Rao Bound</a></li>
<li class="chapter" data-level="8.4.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#rao-blackwell-and-lehmann-scheffé-theorem"><i class="fa fa-check"></i><b>8.4.2</b> Rao-Blackwell and Lehmann-Scheffé Theorem</a></li>
<li class="chapter" data-level="8.4.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-ii-using-the-lehmann-scheffé-theorem"><i class="fa fa-check"></i><b>8.4.3</b> Finding UMVUEs II: Using the Lehmann-Scheffé Theorem</a></li>
<li class="chapter" data-level="8.4.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-iii-lehmann-scheffé-corollary"><i class="fa fa-check"></i><b>8.4.4</b> Finding UMVUEs III: Lehmann-Scheffé Corollary</a></li>
<li class="chapter" data-level="8.4.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#proving-an-umvue-does-not-exist"><i class="fa fa-check"></i><b>8.4.5</b> Proving an UMVUE Does Not Exist</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#inferential-properties-of-exponential-families-distributions"><i class="fa fa-check"></i><b>8.5</b> Inferential Properties of Exponential Families Distributions</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#bernoulli-1"><i class="fa fa-check"></i><b>8.5.1</b> Bernoulli</a></li>
<li class="chapter" data-level="8.5.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#binomial-1"><i class="fa fa-check"></i><b>8.5.2</b> Binomial</a></li>
<li class="chapter" data-level="8.5.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#geometric"><i class="fa fa-check"></i><b>8.5.3</b> Geometric</a></li>
<li class="chapter" data-level="8.5.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#negative-binomial-1"><i class="fa fa-check"></i><b>8.5.4</b> Negative Binomial</a></li>
<li class="chapter" data-level="8.5.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#poisson-1"><i class="fa fa-check"></i><b>8.5.5</b> Poisson</a></li>
<li class="chapter" data-level="8.5.6" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#normal-1"><i class="fa fa-check"></i><b>8.5.6</b> Normal</a></li>
<li class="chapter" data-level="8.5.7" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#exponential-1"><i class="fa fa-check"></i><b>8.5.7</b> Exponential</a></li>
<li class="chapter" data-level="8.5.8" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#gamma-1"><i class="fa fa-check"></i><b>8.5.8</b> Gamma</a></li>
<li class="chapter" data-level="8.5.9" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#pareto-1"><i class="fa fa-check"></i><b>8.5.9</b> Pareto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html"><i class="fa fa-check"></i><b>9</b> Point Estimators: Asymptotics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#consistency"><i class="fa fa-check"></i><b>9.1</b> Consistency</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>9.1.1</b> Technique: Weak Law of Large Numbers</a></li>
<li class="chapter" data-level="9.1.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-direct-proof-via-convergence-in-probability"><i class="fa fa-check"></i><b>9.1.2</b> Technique: Direct Proof via Convergence in Probability</a></li>
<li class="chapter" data-level="9.1.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-continuous-mapping-theorem."><i class="fa fa-check"></i><b>9.1.3</b> Technique: Continuous Mapping Theorem.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-efficiency"><i class="fa fa-check"></i><b>9.2</b> Asymptotic Efficiency</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#central-limit-theorems"><i class="fa fa-check"></i><b>9.2.1</b> Central Limit Theorems</a></li>
<li class="chapter" data-level="9.2.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#the-delta-method"><i class="fa fa-check"></i><b>9.2.2</b> The Delta Method</a></li>
<li class="chapter" data-level="9.2.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#cramer-wold-device"><i class="fa fa-check"></i><b>9.2.3</b> Cramer-Wold Device</a></li>
<li class="chapter" data-level="9.2.4" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-distribution-in-practice"><i class="fa fa-check"></i><b>9.2.4</b> Asymptotic Distribution in Practice</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-properties-of-mles"><i class="fa fa-check"></i><b>9.3</b> Asymptotic Properties of MLEs</a></li>
<li class="chapter" data-level="9.4" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#variance-stabilizing-transformations"><i class="fa fa-check"></i><b>9.4</b> Variance Stabilizing Transformations</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Tests: Finite Samples</a>
<ul>
<li class="chapter" data-level="10.1" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#constructing-a-test"><i class="fa fa-check"></i><b>10.1</b> Constructing a Test</a></li>
<li class="chapter" data-level="10.2" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#lrt"><i class="fa fa-check"></i><b>10.2</b> Likelihood Ratio Tests</a></li>
<li class="chapter" data-level="10.3" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#power"><i class="fa fa-check"></i><b>10.3</b> Power</a></li>
<li class="chapter" data-level="10.4" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#how-to-find-optimal-tests"><i class="fa fa-check"></i><b>10.4</b> How to Find Optimal Tests</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#properties-1"><i class="fa fa-check"></i><b>10.4.1</b> Properties</a></li>
<li class="chapter" data-level="10.4.2" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-simple-hypotheses-the-neyman-pearson-lemma"><i class="fa fa-check"></i><b>10.4.2</b> Optimality for Simple Hypotheses: The Neyman-Pearson Lemma</a></li>
<li class="chapter" data-level="10.4.3" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-one-sided-hypotheses-the-karlin-rubin-theorem"><i class="fa fa-check"></i><b>10.4.3</b> Optimality for One-Sided Hypotheses: The Karlin-Rubin Theorem</a></li>
<li class="chapter" data-level="10.4.4" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-two-sided-hypotheses."><i class="fa fa-check"></i><b>10.4.4</b> Optimality for Two-Sided Hypotheses.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#nuisance-parameters"><i class="fa fa-check"></i><b>10.5</b> Nuisance Parameters</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Tests: Asymptotics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#wald-test"><i class="fa fa-check"></i><b>11.1</b> Wald Test</a></li>
<li class="chapter" data-level="11.2" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#score-test"><i class="fa fa-check"></i><b>11.2</b> Score Test</a></li>
<li class="chapter" data-level="11.3" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>11.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="11.4" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#composite-null-hypotheses"><i class="fa fa-check"></i><b>11.4</b> Composite Null Hypotheses</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#multiple-parameters"><i class="fa fa-check"></i><b>11.4.1</b> Multiple Parameters</a></li>
<li class="chapter" data-level="11.4.2" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#nuisance-parameters-1"><i class="fa fa-check"></i><b>11.4.2</b> Nuisance Parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>12</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="12.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#definition-1"><i class="fa fa-check"></i><b>12.1</b> Definition</a></li>
<li class="chapter" data-level="12.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#test-inversion"><i class="fa fa-check"></i><b>12.2</b> When You’ve Constructed a Hypothesis Test…</a></li>
<li class="chapter" data-level="12.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#when-youve-found-a-pivot-including-asymptotic-normality"><i class="fa fa-check"></i><b>12.3</b> When You’ve Found a Pivot (Including Asymptotic Normality)…</a></li>
<li class="chapter" data-level="12.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#when-all-you-have-is-a-distribution"><i class="fa fa-check"></i><b>12.4</b> When All You Have Is a Distribution…</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="random-processes.html"><a href="random-processes.html"><i class="fa fa-check"></i><b>13</b> Random Processes</a>
<ul>
<li class="chapter" data-level="13.1" data-path="random-processes.html"><a href="random-processes.html#branching-process"><i class="fa fa-check"></i><b>13.1</b> Branching Processes</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="random-processes.html"><a href="random-processes.html#random-variables-1"><i class="fa fa-check"></i><b>13.1.1</b> Random Variables</a></li>
<li class="chapter" data-level="13.1.2" data-path="random-processes.html"><a href="random-processes.html#probability-generating-function"><i class="fa fa-check"></i><b>13.1.2</b> Probability Generating Function</a></li>
<li class="chapter" data-level="13.1.3" data-path="random-processes.html"><a href="random-processes.html#finding-the-pgf-of-a-branching-process"><i class="fa fa-check"></i><b>13.1.3</b> Finding the PGF of a Branching Process</a></li>
<li class="chapter" data-level="13.1.4" data-path="random-processes.html"><a href="random-processes.html#finding-the-probability-of-extinction-criticality-theorem"><i class="fa fa-check"></i><b>13.1.4</b> Finding the Probability of Extinction: Criticality Theorem</a></li>
<li class="chapter" data-level="13.1.5" data-path="random-processes.html"><a href="random-processes.html#example"><i class="fa fa-check"></i><b>13.1.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="random-processes.html"><a href="random-processes.html#poisson-processes"><i class="fa fa-check"></i><b>13.2</b> Poisson Processes</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="random-processes.html"><a href="random-processes.html#memorylessness-of-the-exponential"><i class="fa fa-check"></i><b>13.2.1</b> Memorylessness of the Exponential</a></li>
<li class="chapter" data-level="13.2.2" data-path="random-processes.html"><a href="random-processes.html#count-time-duality"><i class="fa fa-check"></i><b>13.2.2</b> Count-Time Duality</a></li>
<li class="chapter" data-level="13.2.3" data-path="random-processes.html"><a href="random-processes.html#poisson-distribution"><i class="fa fa-check"></i><b>13.2.3</b> Poisson Distribution</a></li>
<li class="chapter" data-level="13.2.4" data-path="random-processes.html"><a href="random-processes.html#exponential-distribution"><i class="fa fa-check"></i><b>13.2.4</b> Exponential Distribution</a></li>
<li class="chapter" data-level="13.2.5" data-path="random-processes.html"><a href="random-processes.html#example-1"><i class="fa fa-check"></i><b>13.2.5</b> Example</a></li>
<li class="chapter" data-level="13.2.6" data-path="random-processes.html"><a href="random-processes.html#merging-and-splitting"><i class="fa fa-check"></i><b>13.2.6</b> Merging and Splitting</a></li>
<li class="chapter" data-level="13.2.7" data-path="random-processes.html"><a href="random-processes.html#thinning"><i class="fa fa-check"></i><b>13.2.7</b> Thinning</a></li>
<li class="chapter" data-level="13.2.8" data-path="random-processes.html"><a href="random-processes.html#restarting"><i class="fa fa-check"></i><b>13.2.8</b> Restarting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Solving Statistical Problems</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-processes" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Chapter 13</span> Random Processes<a href="random-processes.html#random-processes" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>A <em>random process</em> is a set or sequence of random variables indexed by time. That is, <span class="math inline">\(X(t)\)</span> or <span class="math inline">\(X_t\)</span> is a random variable indexed by time <span class="math inline">\(t\)</span>, or sometimes <span class="math inline">\(X(n)\)</span> or <span class="math inline">\(X_n\)</span> indexed by generation <span class="math inline">\(n\)</span> as in the branching process which we discuss first. Several techniques have been developed to analyze these special types of random variables.</p>
<div id="branching-process" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Branching Processes<a href="random-processes.html#branching-process" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Also known as a “<a href="https://en.wikipedia.org/wiki/Galton%E2%80%93Watson_process">Galton-Watson process</a>”, a branching process uses random variables to model population growth. Let’s start with notation.</p>
<div id="random-variables-1" class="section level3 hasAnchor" number="13.1.1">
<h3><span class="header-section-number">13.1.1</span> Random Variables<a href="random-processes.html#random-variables-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’ll start by defining the random variables that characterize a branching process.</p>
<ul>
<li><span class="math inline">\(X_n\)</span> = size of the population at time (or generation) <span class="math inline">\(n\)</span></li>
<li><span class="math inline">\(Y_{i,n-1}\)</span> = number of offspring produced by the <span class="math inline">\(i^{th}\)</span> individual in generation <span class="math inline">\(n-1\)</span></li>
</ul>
<p> </p>
<p>How are random variables <span class="math inline">\(X_n\)</span> and <span class="math inline">\(Y_{i,n-1}\)</span> related? Intuitively, we can think of the population size of the current generation (<span class="math inline">\(n\)</span>) as the sum of the offspring produced by each individual in the previous generation (<span class="math inline">\(n-1\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
X_n &amp;= \sum_{i=1}^{X_{n-1}} Y_{i,n-1}\\
&amp;= Y_{1,n-1} + Y_{2,n-1} +...+Y_{X_{n-1},n-1}
\end{aligned}
\]</span>
This is a recursive relation, where the number of summands depends on the previous value <span class="math inline">\(X_{n-1}\)</span>. Typically, we assume <span class="math inline">\(X_n = 1\)</span>. This recursive property necessiates the use of a special tool to analyze <span class="math inline">\(X_n\)</span>: the probability generating function.</p>
</div>
<div id="probability-generating-function" class="section level3 hasAnchor" number="13.1.2">
<h3><span class="header-section-number">13.1.2</span> Probability Generating Function<a href="random-processes.html#probability-generating-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <strong>Probability Generating Function</strong> (PGF) allows us to compute probabilities from branching processes. It is defined as</p>
<p><span class="math display">\[
g_X(t)=\mathbb{E}_X\left(t^X\right)=\sum_{n=0}^{\infty} t^n P(X=n)
\]</span>
What makes the PGF so useful for branching processes is that its derivative evaluated at 0 yields the probability of that <span class="math inline">\(X\)</span> takes on a particular value - that is,</p>
<p><span class="math display">\[
P(X = k) = \frac{1}{k!}\cdot\frac{d^k}{dt^k}g_X(0)
\]</span></p>
<p>Similar to MGFs, independent random variables can be convoluted by multiplying their PGFs. If <span class="math inline">\(Y = X_1 + X_2\)</span>, then</p>
<p><span class="math display">\[
g_Y(t) = g_{X_1}(t)\cdot g_{X_2}(t)
\]</span>
and by extension, if <span class="math inline">\(Y = \sum_{i=1}^nX_i\)</span> and <span class="math inline">\(X_i\)</span> are iid, then</p>
<p><span class="math display">\[
g_Y(t) = (g_{X_i}(t))^n
\]</span></p>
<p>For i.i.d. <span class="math inline">\(Y_{i,j}\)</span>, the PGF also gives the first two moments:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}\left(X_n\right) &amp; =[\mathbb{E}(Y)]^n \\
\operatorname{Var}\left(X_n\right) &amp; =\operatorname{Var}(Y)\left(\sum_{i=n-1}^{2(n-1)}[\mathbb{E}(Y)]^i\right)
\end{aligned}
\]</span>
 </p>
<p>Asymptotics exists for Branching Processes on i.i.d. <span class="math inline">\(\left\{Y_{i,j}\right\}\)</span> with finite variance:
<span class="math display">\[
\begin{gathered}
\text{Population-Level} \quad \quad \text{Individual-Level} \\
\\
\mathrm{E}\left(X_n\right) \rightarrow \begin{cases}0 &amp; \mathrm{E}(Y)&lt;1 \\
1 &amp; \mathrm{E}(Y)=1 \\
\infty &amp; \mathrm{E}(Y)&gt;1\end{cases} \\
\\
\operatorname{Var}\left(X_n\right) \rightarrow \begin{cases}0 &amp; \mathrm{E}(Y)&lt;1 \\
\infty &amp; \mathrm{E}(Y) \geq 1\end{cases}
\end{gathered}
\]</span>
This allows us to analyze the long-run behavior of the branching process as <span class="math inline">\(n\rightarrow \infty\)</span></p>
</div>
<div id="finding-the-pgf-of-a-branching-process" class="section level3 hasAnchor" number="13.1.3">
<h3><span class="header-section-number">13.1.3</span> Finding the PGF of a Branching Process<a href="random-processes.html#finding-the-pgf-of-a-branching-process" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As a result of the recursive property of the branching process, where the number of children produced in generation <span class="math inline">\(n\)</span> depends on the number in <span class="math inline">\(n-1\)</span>, it turns out that the PGF of a branching process is</p>
<p><span class="math display">\[g_{X_n}(t) = g_{X_{n-1}}(g_{Y}(t))\]</span>
With this, a number of techniques are possible:</p>
<ul>
<li>We can find the probability that a given generation is of size <span class="math inline">\(k\)</span> by computing the probability generating function of <span class="math inline">\(X_n\)</span> and differentiating, as mentioned above.</li>
<li>We may be able to use <a href="#induction">Mathematical Induction</a> to derive the full PGF of the branching process for arbitrary <span class="math inline">\(n\)</span>.</li>
<li>We can compute the probability of extinction, as we discuss in the next section</li>
</ul>
</div>
<div id="finding-the-probability-of-extinction-criticality-theorem" class="section level3 hasAnchor" number="13.1.4">
<h3><span class="header-section-number">13.1.4</span> Finding the Probability of Extinction: Criticality Theorem<a href="random-processes.html#finding-the-probability-of-extinction-criticality-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The Criticality Theorem states that the probability of ultimate extinction of a branching process is the smallest solution to</p>
<p><span class="math display">\[\eta=g_Y(\eta)\]</span></p>
<p>In general, we can solve for <span class="math inline">\(\eta\)</span> by factoring the equation, or by using the quadratic equation:</p>
<p><span class="math display">\[
\begin{aligned}
&amp;0=a\eta^2+b\eta+c\\
\\
&amp;\eta=\frac{-b \pm \sqrt{b^2-4 a c}}{2 a}
\end{aligned}
\]</span></p>
</div>
<div id="example" class="section level3 hasAnchor" number="13.1.5">
<h3><span class="header-section-number">13.1.5</span> Example<a href="random-processes.html#example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a Branching Process where individuals duplicate with probability <span class="math inline">\(p\)</span> and die with probability <span class="math inline">\(q\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li>Describe the mean and variance over time for this branching process. For what values of <span class="math inline">\(p\)</span> will the process go extinct with probability 1?</li>
<li>Establish the probability of eventual extinction for arbitrary <span class="math inline">\(p\)</span>.</li>
</ol>
<p> </p>
<p><strong>Step 1</strong>: Define the pmf of <span class="math inline">\(Y\)</span> based on the given reproduction probabilities. Does <span class="math inline">\(Y\)</span> follow a known distribution?</p>
<p><span class="math inline">\(f_y(y)=\left\{\begin{array}{ll}y=0 &amp; \text { w.p. } q=1-p \\ y=2 &amp; \text { w.p. } p\end{array} \quad \Rightarrow \quad y \sim 2\right.\)</span> Bernoulli<span class="math inline">\((p)\)</span></p>
<p> </p>
<p><strong>Step 2</strong>: Calculate the moments of <span class="math inline">\(Y\)</span>, which can be used to calculate the moments of <span class="math inline">\(X_n\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
\mathbb{E}[Y]=2 p \quad \quad \quad \quad \mathbb{E}\left[X_n\right] &amp; =(2 p)^n \\
\operatorname{Var}(Y)=4 p q \quad \quad \operatorname{Var}\left(X_n\right) &amp; =\operatorname{Var}(y) \sum_{i=n-1}^{2(n-1)} \mathbb{E}[Y]^i \\
&amp; =4 p q \sum_{i=n-1}^{2(n-1)}(2 p)^i
\end{aligned}
\]</span></p>
<p>Based on our asymptotic results, we know that the process <span class="math inline">\(X_n\)</span> will go extinct with probability 1 if <span class="math inline">\(\mathbb{E}[Y]&lt;1\)</span></p>
<p><span class="math display">\[
\mathbb{E}[Y]=2 p \Rightarrow \text { process will go extinct with probability 1 if } p&lt; \frac{1}{2}
\]</span></p>
<p> </p>
<p><strong>Step 3</strong>: Find the probability of ultimate extinction using Criticality Theorem.</p>
<p>First, find the PGF of <span class="math inline">\(Y\)</span>:
<span class="math display">\[
\begin{aligned}
g_Y(\eta) =\mathbb{E}\left[\eta^Y\right]&amp;=\sum_Y \eta^Y f_Y(y) \\
&amp; =\eta^2 P(Y=2)+\eta^0 P(Y=0) \\
&amp; =\eta^2 p+q
\end{aligned}
\]</span></p>
<p>Second, find the probability of ultimate extinction, which is the smallest solution to <span class="math inline">\(\eta=g_Y(\eta)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\eta&amp;=\eta^2 p+q \\
0&amp;=\eta^2 p-\eta+q\\
\\
a&amp;=p, b=-1, c=q\\
\\
\eta&amp;= \frac{1 \pm \sqrt{1-4pq}}{2p} \\&amp;= \frac{1 \pm \sqrt{1-4p(1-p)}}{2p} \\&amp;= \frac{1 \pm \sqrt{1-4p+4p^2}}{2p} \\&amp;= \frac{1 \pm \sqrt{(2p-1)^2}}{2p} \\&amp;= \frac{1 \pm (2p-1)}{2p}\\
&amp;=\text{min}\left(1 \quad \text{or} \quad \frac{1}{p}-1\right)
\end{aligned}
\]</span></p>
<p>For <span class="math inline">\(p \leq \frac{1}{2}, 1\)</span> is the minimum. Thus, <span class="math inline">\(\eta=P(\text{Extinction})=1.\)</span></p>
</div>
</div>
<div id="poisson-processes" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Poisson Processes<a href="random-processes.html#poisson-processes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>Poisson Process</strong> is a model for a series of discrete events where the average time between events is known, but the exact timing of events is random. In a Poisson process,</p>
<p><span class="math display">\[X(t) = \text{# of occurrences in } (0, t] \]</span></p>
<p>All Poisson processes feature an intensity <span class="math inline">\(\lambda\)</span> which controls the frequency at which events occur.</p>
<p><strong>Definition</strong>: A Poisson process with intensity <span class="math inline">\(\lambda\)</span> is defined by the following properties, which are all equivalent:</p>
<ul>
<li>Events are independent of each other. That is, all <span class="math inline">\(X(t_k) - X(t_{k-1})\)</span> are independent for all <span class="math inline">\(k\)</span>. Note that <span class="math inline">\(X(t_k) - X(t_{k-1}) \sim \text{Poisson}(\lambda(t_k-t_{k-1}))\)</span></li>
<li><span class="math inline">\(P(1\text{ occurence in }(t, t+h]) = \lambda h + o(h)\)</span> as <span class="math inline">\(h\rightarrow0\)</span>, while <span class="math inline">\(P(\geq2\text{ occurence in }(t, t+h]) = o(h)\)</span></li>
<li>If <span class="math inline">\(T_k\)</span> is the time between the <span class="math inline">\(k-1\)</span> and <span class="math inline">\(k\)</span>th occurrences, then <span class="math inline">\(T_k\sim \text{Exp}(\frac{1}{\lambda})\)</span></li>
</ul>
<p>Note that two events cannot occur at the same time. We often assume that the average rate (events per time period) is constant, though this assumption will later be relaxed. Let’s discuss the implications of this definition.</p>
<div id="memorylessness-of-the-exponential" class="section level3 hasAnchor" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Memorylessness of the Exponential<a href="random-processes.html#memorylessness-of-the-exponential" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that the exponential distribution is <strong>memoryless</strong>, meaning <span class="math inline">\(P(X&gt;x+a \mid X&gt;a)=P(X&gt;x)\)</span>. The memoryless property of the exponential distribution applies to waiting times in a Poisson process. It means that the time between events remains independent of past events, allowing us to predict future waiting times solely based on the average rate of event occurrences (i.e., the interarrival times between events are i.i.d.).</p>
</div>
<div id="count-time-duality" class="section level3 hasAnchor" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Count-Time Duality<a href="random-processes.html#count-time-duality" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[
\{T_n&gt;t\}=\{N_t&lt;n\}
\]</span></p>
<p>In words, the following 2 statements are equivalent:</p>
<ul>
<li><span class="math inline">\(T_n\)</span> (time to the <span class="math inline">\(n^{th}\)</span> event) is greater than some fixed time <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(N_t\)</span> (number of events up to time <span class="math inline">\(t\)</span>) is less than some fixed number <span class="math inline">\(n\)</span></li>
</ul>
<p><span class="math display">\[
\int_t^{\infty} \underbrace{\frac{1}{\Gamma(n)\lambda^{-n}}  x^{n-1} e^{-\lambda x}}_{T_n \sim \text{Gamma}(n,\lambda)} d x
\quad = \quad \sum_{x=0}^{n-1} \underbrace{\frac{e^{-\lambda t} (\lambda t)^x}{x!}}_{N_t \sim \text{Poisson}(\lambda t)}
\]</span></p>
</div>
<div id="poisson-distribution" class="section level3 hasAnchor" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Poisson Distribution<a href="random-processes.html#poisson-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that we are interested in the expected <strong>number of events</strong> that will occur over a particular interval. The probability of observing a particular number of events can be modeled using the (discrete) poisson distribution:</p>
<ul>
<li><span class="math inline">\(X=\)</span> Discrete number of events occurring over a finite interval</li>
<li>Moments: <span class="math inline">\(\mathbb{E}[X]=\lambda\)</span>, <span class="math inline">\(\operatorname{Var}(X)=\lambda\)</span></li>
<li><span class="math inline">\(\lambda=\)</span> Expected number of events over interval <span class="math inline">\(=\underbrace{\frac{Events}{Time}}_{Rate}\times Time\)</span></li>
</ul>
<p> </p>
<p><img src="Solving-Statistical-Problems_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="exponential-distribution" class="section level3 hasAnchor" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> Exponential Distribution<a href="random-processes.html#exponential-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that we are interested in the expected <strong>time before the next event</strong>. The probability of observing a particular time before the next event can be modeled using the (continuous) exponential distribution:</p>
<ul>
<li><span class="math inline">\(X=\)</span> Continuous time between events</li>
<li>Moments: <span class="math inline">\(\mathbb{E}[X]=\frac{1}{\lambda}\)</span>, <span class="math inline">\(\operatorname{Var}(X)=\frac{1}{\lambda^2}\)</span></li>
<li><span class="math inline">\(\lambda=\)</span> Rate of events <span class="math inline">\(=\underbrace{\frac{Events}{Time}}_{Rate}\)</span></li>
</ul>
<p><em>Note: There is an inverse relationship between the rate of events (<span class="math inline">\(\lambda\)</span>) and expected time before the next event (<span class="math inline">\(x\)</span>). As the rate of events (<span class="math inline">\(\lambda\)</span>) increases, the time before the next event (<span class="math inline">\(x\)</span>) decreases.</em></p>
<p> </p>
<p><img src="Solving-Statistical-Problems_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p> </p>
</div>
<div id="example-1" class="section level3 hasAnchor" number="13.2.5">
<h3><span class="header-section-number">13.2.5</span> Example<a href="random-processes.html#example-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consider a Poisson process <span class="math inline">\((\lambda)\)</span> with a twist: After every event there is a guaranteed period of length <span class="math inline">\(\nu\)</span> during which no event can occur.</p>
<p>Typical Poisson process:</p>
<ul>
<li>Distribution of time between events: <span class="math inline">\(T_n-T_{n-1} \sim \operatorname{Exp}(\lambda)\)</span></li>
<li>Distribution of time to the <span class="math inline">\(n^{th}\)</span> event: <span class="math inline">\(\sum_{i=1}^n T_i \sim \operatorname{Gamma}(n, \lambda)\)</span></li>
</ul>
<p>Poisson process with a twist:</p>
<ul>
<li>Distribution of time between events: <span class="math inline">\(T_n-T_{n-1} \sim \operatorname{Exp}(\lambda)+\nu\)</span></li>
</ul>
<p><span class="math display">\[
f_{T_n-T_{n-1}}(x)=\lambda e^{-\lambda(x-\nu)}
\]</span></p>
<ul>
<li>Distribution of time to the <span class="math inline">\(n^{th}\)</span> event: <span class="math inline">\(\sum_{i=1}^n T_i \sim \operatorname{Gamma}(n, \lambda)+n \nu\)</span></li>
</ul>
<p><span class="math display">\[
f_{T_n}(x)=\frac{1}{\Gamma(n) \lambda^{-n}}(x-n \nu)^{n-1} e^{-\lambda(x-n \nu)}
\]</span></p>
<p>Further, by count time duality, we can write:</p>
<p><span class="math display">\[
P(T_n&gt;t)=P(N_t&lt;n)
\]</span></p>
<p><span class="math display">\[
\int_t^{\infty} \frac{1}{\Gamma(n)\lambda^{-n}}  (x-n \nu)^{n-1} e^{-\lambda (x-n \nu)} d x
\quad = \quad \sum_{x=0}^{n-1} \frac{e^{-\lambda (t-n \nu)} (\lambda (t-n \nu))^x}{x!}
\]</span></p>
<p>Next, we’ll state some further results about Poisson processes (note that these are from the notes of Isabella Nogues)</p>
</div>
<div id="merging-and-splitting" class="section level3 hasAnchor" number="13.2.6">
<h3><span class="header-section-number">13.2.6</span> Merging and Splitting<a href="random-processes.html#merging-and-splitting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we have <span class="math inline">\(m\)</span> independent Poisson processes <span class="math inline">\(X_1(t),...,X_m(t)\)</span> with intensities <span class="math inline">\(\lambda_1,...,\lambda_m\)</span>. Let</p>
<p><span class="math display">\[Y(t) = \sum_{i=1}^m X_i(t)\]</span></p>
<p>Then <span class="math inline">\(Y(t)\)</span> is a merged Poisson process with intensity <span class="math inline">\(\sum_{i=1}^m \lambda_i\)</span>.</p>
<p>In addition to merging as in the above, we may also be interested in the probability that a particular Poisson process <span class="math inline">\(k\)</span> procedures an event before others - this is “splitting”. In general, such probabilities are modeled as <span class="math inline">\(Geometric\)</span> random variables involving a function of the parameter</p>
<p><span class="math display">\[p_k = \frac{\lambda_k}{\sum_{i=1}^n\lambda_i}\]</span>
- <span class="math inline">\(p_k\)</span> represents the probability that the first occurrence is caused by <span class="math inline">\(X_k(t)\)</span>.
- <span class="math inline">\(p_k^n\)</span> is the probability that the first <span class="math inline">\(n\)</span> occurrences are caused by <span class="math inline">\(X_k(t)\)</span>.</p>
<p>Then,</p>
<ul>
<li>The number of occurrences from any <span class="math inline">\(X_i(t)\)</span>, <span class="math inline">\(i\neq k\)</span> preceding an occurrence from <span class="math inline">\(X_k(t)\)</span> is <span class="math inline">\(Z \sim \text{Geo}(p_k)\)</span></li>
<li>The number of occurrences from any <span class="math inline">\(X_j(t)\)</span> between two occurrences in <span class="math inline">\(X_k(t)\)</span> is <span class="math inline">\(Z \sim \text{Geo}(p_k)\)</span></li>
<li>The number of occurrences from <span class="math inline">\(X_k(t)\)</span> preceding an occurrence from the <span class="math inline">\(k-1\)</span> other processes is <span class="math inline">\(Z \sim \text{Geo}(1-p_k)\)</span></li>
</ul>
<p>Note that here the Geometric distribution is parametrized as <span class="math inline">\(f_X(x|p) = (1-p)^x\)</span>.</p>
</div>
<div id="thinning" class="section level3 hasAnchor" number="13.2.7">
<h3><span class="header-section-number">13.2.7</span> Thinning<a href="random-processes.html#thinning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(X(t)\)</span> be a Poisson process in which not every occurrence is observed. Let <span class="math inline">\(Y(t)\)</span> be the number of observed occurrences, and <span class="math inline">\(Z(t)\)</span> the number of unobserved occurrences. If each occurrence is observed with probability <span class="math inline">\(p\)</span>, then <span class="math inline">\(Y(t)\)</span> and <span class="math inline">\(Z(t)\)</span> are Poisson processes with intensities <span class="math inline">\(\lambda p\)</span> and <span class="math inline">\(\lambda(1-p)\)</span></p>
</div>
<div id="restarting" class="section level3 hasAnchor" number="13.2.8">
<h3><span class="header-section-number">13.2.8</span> Restarting<a href="random-processes.html#restarting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If <span class="math inline">\(X(t)\)</span> is a Poisson Process, then all of the following are also Poisson processes:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X(t + s) - X(s)\)</span></li>
<li><span class="math inline">\(X(T_k + t) - X(t)\)</span></li>
<li><span class="math inline">\(X(T + t) + X(t)\)</span> for <span class="math inline">\(T \geq 0\)</span> random variable independent of <span class="math inline">\(X(t)\)</span></li>
<li><span class="math inline">\(X(T_k^* + t) - X(T_k^*)\)</span> or <span class="math inline">\(T \geq 0\)</span> random variable independent of <span class="math inline">\(X(t)\)</span> and <span class="math inline">\(T_k^* = \min(T_k, T)\)</span></li>
</ol>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="confidence-intervals.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/13-random-processes.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Solving-Statistical-Problems.pdf", "Solving-Statistical-Problems.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
