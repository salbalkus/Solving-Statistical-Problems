<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Math Tricks | Solving Statistical Problems</title>
  <meta name="description" content="Chapter 2 Math Tricks | Solving Statistical Problems" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Math Tricks | Solving Statistical Problems" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 2 Math Tricks | Solving Statistical Problems" />
  <meta name="github-repo" content="salbalkus/Solving-Statistical-Problems" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Math Tricks | Solving Statistical Problems" />
  
  <meta name="twitter:description" content="Chapter 2 Math Tricks | Solving Statistical Problems" />
  

<meta name="author" content="Salvador Balkus, Kimberly Greco, and Mónica Robles Fontán" />


<meta name="date" content="2023-08-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="probability.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Solving Statistical Problems</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="math-tricks.html"><a href="math-tricks.html"><i class="fa fa-check"></i><b>2</b> Math Tricks</a>
<ul>
<li class="chapter" data-level="2.1" data-path="math-tricks.html"><a href="math-tricks.html#combinatorics"><i class="fa fa-check"></i><b>2.1</b> Combinatorics</a></li>
<li class="chapter" data-level="2.2" data-path="math-tricks.html"><a href="math-tricks.html#binomial-and-multinomial-theorems"><i class="fa fa-check"></i><b>2.2</b> Binomial and Multinomial Theorems</a></li>
<li class="chapter" data-level="2.3" data-path="math-tricks.html"><a href="math-tricks.html#geometric-series"><i class="fa fa-check"></i><b>2.3</b> Geometric Series</a></li>
<li class="chapter" data-level="2.4" data-path="math-tricks.html"><a href="math-tricks.html#exponential-taylor"><i class="fa fa-check"></i><b>2.4</b> Taylor Series for Exponential Function</a></li>
<li class="chapter" data-level="2.5" data-path="math-tricks.html"><a href="math-tricks.html#taylors-formula"><i class="fa fa-check"></i><b>2.5</b> Taylor’s Formula</a></li>
<li class="chapter" data-level="2.6" data-path="math-tricks.html"><a href="math-tricks.html#exponential-limit"><i class="fa fa-check"></i><b>2.6</b> Exponential Limit</a></li>
<li class="chapter" data-level="2.7" data-path="math-tricks.html"><a href="math-tricks.html#ibp"><i class="fa fa-check"></i><b>2.7</b> Integration by Parts</a></li>
<li class="chapter" data-level="2.8" data-path="math-tricks.html"><a href="math-tricks.html#leibniz-rule"><i class="fa fa-check"></i><b>2.8</b> Leibniz’s Rule</a></li>
<li class="chapter" data-level="2.9" data-path="math-tricks.html"><a href="math-tricks.html#fubinis-theorem"><i class="fa fa-check"></i><b>2.9</b> Fubini’s Theorem</a></li>
<li class="chapter" data-level="2.10" data-path="math-tricks.html"><a href="math-tricks.html#gamma-function"><i class="fa fa-check"></i><b>2.10</b> Gamma Function</a></li>
<li class="chapter" data-level="2.11" data-path="math-tricks.html"><a href="math-tricks.html#triangle-inequality"><i class="fa fa-check"></i><b>2.11</b> Triangle Inequality</a></li>
<li class="chapter" data-level="2.12" data-path="math-tricks.html"><a href="math-tricks.html#constrained-optimization"><i class="fa fa-check"></i><b>2.12</b> Constrained Optimization</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#basic-axioms"><i class="fa fa-check"></i><b>3.1</b> Basic Axioms</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#basic-probability-solving-techniques"><i class="fa fa-check"></i><b>3.2</b> Basic Probability Solving Techniques</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#disjointify"><i class="fa fa-check"></i><b>3.2.1</b> Disjointification</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#demorgan"><i class="fa fa-check"></i><b>3.2.2</b> DeMorgan’s Laws</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#proving-inequalities-subsetting"><i class="fa fa-check"></i><b>3.2.3</b> Proving Inequalities: Subsetting</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>3.3</b> Conditional Probability</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="probability.html"><a href="probability.html#conditional-probability-in-practice"><i class="fa fa-check"></i><b>3.3.1</b> Conditional Probability in Practice</a></li>
<li class="chapter" data-level="7.1.2" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>7.1.2</b> Exponential Family Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.3" data-path="statistics.html"><a href="statistics.html#a-note-on-distributions-of-sufficient-statistics"><i class="fa fa-check"></i><b>7.1.3</b> A Note on Distributions of Sufficient Statistics</a></li>
<li class="chapter" data-level="7.1.4" data-path="statistics.html"><a href="statistics.html#moments-of-the-sufficient-statistic"><i class="fa fa-check"></i><b>7.1.4</b> Moments of the Sufficient Statistic</a></li>
<li class="chapter" data-level="7.1.5" data-path="statistics.html"><a href="statistics.html#table-ss"><i class="fa fa-check"></i><b>7.1.5</b> Table of Sufficient Statistics</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="statistics.html"><a href="statistics.html#minimal-sufficiency"><i class="fa fa-check"></i><b>7.2</b> Minimal Sufficiency</a></li>
<li class="chapter" data-level="7.3" data-path="statistics.html"><a href="statistics.html#ancillary-stats"><i class="fa fa-check"></i><b>7.3</b> Ancillary Statistics</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="statistics.html"><a href="statistics.html#why-are-we-interested-in-ancillary-statistics"><i class="fa fa-check"></i><b>7.3.1</b> Why are we interested in ancillary statistics?</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="statistics.html"><a href="statistics.html#complete-stats"><i class="fa fa-check"></i><b>7.4</b> Complete Statistics</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="statistics.html"><a href="statistics.html#techniques-for-finding-css"><i class="fa fa-check"></i><b>7.4.1</b> Techniques for Finding CSS</a></li>
<li class="chapter" data-level="7.4.2" data-path="statistics.html"><a href="statistics.html#basus-theorem"><i class="fa fa-check"></i><b>7.4.2</b> Basu’s Theorem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html"><i class="fa fa-check"></i><b>8</b> Point Estimators: Finite Samples</a>
<ul>
<li class="chapter" data-level="8.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#identifiability"><i class="fa fa-check"></i><b>8.1</b> Identifiability</a></li>
<li class="chapter" data-level="8.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-estimators"><i class="fa fa-check"></i><b>8.2</b> Finding estimators</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#method-of-moments"><i class="fa fa-check"></i><b>8.2.1</b> Method of Moments</a></li>
<li class="chapter" data-level="8.2.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>8.2.2</b> Maximum Likelihood Estimation</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#properties-of-estimators"><i class="fa fa-check"></i><b>8.3</b> Properties of Estimators</a></li>
<li class="chapter" data-level="8.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#uniform-minimum-variance-unbiased-estimators-umvues"><i class="fa fa-check"></i><b>8.4</b> Uniform Minimum Variance Unbiased Estimators (UMVUEs)</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-i-cramér-rao-bound"><i class="fa fa-check"></i><b>8.4.1</b> Finding UMVUEs I: Cramér-Rao Bound</a></li>
<li class="chapter" data-level="8.4.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#rao-blackwell-and-lehmann-scheffé-theorem"><i class="fa fa-check"></i><b>8.4.2</b> Rao-Blackwell and Lehmann-Scheffé Theorem</a></li>
<li class="chapter" data-level="8.4.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-ii-using-the-lehmann-scheffé-theorem"><i class="fa fa-check"></i><b>8.4.3</b> Finding UMVUEs II: Using the Lehmann-Scheffé Theorem</a></li>
<li class="chapter" data-level="8.4.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#finding-umvues-iii-lehmann-scheffé-corollary"><i class="fa fa-check"></i><b>8.4.4</b> Finding UMVUEs III: Lehmann-Scheffé Corollary</a></li>
<li class="chapter" data-level="8.4.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#proving-an-umvue-does-not-exist"><i class="fa fa-check"></i><b>8.4.5</b> Proving an UMVUE Does Not Exist</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#inferential-properties-of-exponential-families-distributions"><i class="fa fa-check"></i><b>8.5</b> Inferential Properties of Exponential Families Distributions</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#bernoulli-1"><i class="fa fa-check"></i><b>8.5.1</b> Bernoulli</a></li>
<li class="chapter" data-level="8.5.2" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#binomial-1"><i class="fa fa-check"></i><b>8.5.2</b> Binomial</a></li>
<li class="chapter" data-level="8.5.3" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#geometric"><i class="fa fa-check"></i><b>8.5.3</b> Geometric</a></li>
<li class="chapter" data-level="8.5.4" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#negative-binomial-1"><i class="fa fa-check"></i><b>8.5.4</b> Negative Binomial</a></li>
<li class="chapter" data-level="8.5.5" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#poisson-1"><i class="fa fa-check"></i><b>8.5.5</b> Poisson</a></li>
<li class="chapter" data-level="8.5.6" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#normal-1"><i class="fa fa-check"></i><b>8.5.6</b> Normal</a></li>
<li class="chapter" data-level="8.5.7" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#exponential-1"><i class="fa fa-check"></i><b>8.5.7</b> Exponential</a></li>
<li class="chapter" data-level="8.5.8" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#gamma-1"><i class="fa fa-check"></i><b>8.5.8</b> Gamma</a></li>
<li class="chapter" data-level="8.5.9" data-path="point-estimators-finite-samples.html"><a href="point-estimators-finite-samples.html#pareto-1"><i class="fa fa-check"></i><b>8.5.9</b> Pareto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html"><i class="fa fa-check"></i><b>9</b> Point Estimators: Asymptotics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#consistency"><i class="fa fa-check"></i><b>9.1</b> Consistency</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-weak-law-of-large-numbers"><i class="fa fa-check"></i><b>9.1.1</b> Technique: Weak Law of Large Numbers</a></li>
<li class="chapter" data-level="9.1.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-direct-proof-via-convergence-in-probability"><i class="fa fa-check"></i><b>9.1.2</b> Technique: Direct Proof via Convergence in Probability</a></li>
<li class="chapter" data-level="9.1.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#technique-continuous-mapping-theorem."><i class="fa fa-check"></i><b>9.1.3</b> Technique: Continuous Mapping Theorem.</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-efficiency"><i class="fa fa-check"></i><b>9.2</b> Asymptotic Efficiency</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#central-limit-theorems"><i class="fa fa-check"></i><b>9.2.1</b> Central Limit Theorems</a></li>
<li class="chapter" data-level="9.2.2" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#the-delta-method"><i class="fa fa-check"></i><b>9.2.2</b> The Delta Method</a></li>
<li class="chapter" data-level="9.2.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#cramer-wold-device"><i class="fa fa-check"></i><b>9.2.3</b> Cramer-Wold Device</a></li>
<li class="chapter" data-level="9.2.4" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-distribution-in-practice"><i class="fa fa-check"></i><b>9.2.4</b> Asymptotic Distribution in Practice</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#asymptotic-properties-of-mles"><i class="fa fa-check"></i><b>9.3</b> Asymptotic Properties of MLEs</a></li>
<li class="chapter" data-level="9.4" data-path="point-estimators-asymptotics.html"><a href="point-estimators-asymptotics.html#variance-stabilizing-transformations"><i class="fa fa-check"></i><b>9.4</b> Variance Stabilizing Transformations</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Tests: Finite Samples</a>
<ul>
<li class="chapter" data-level="10.1" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#constructing-a-test"><i class="fa fa-check"></i><b>10.1</b> Constructing a Test</a></li>
<li class="chapter" data-level="10.2" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#lrt"><i class="fa fa-check"></i><b>10.2</b> Likelihood Ratio Tests</a></li>
<li class="chapter" data-level="10.3" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#power"><i class="fa fa-check"></i><b>10.3</b> Power</a></li>
<li class="chapter" data-level="10.4" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#how-to-find-optimal-tests"><i class="fa fa-check"></i><b>10.4</b> How to Find Optimal Tests</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#properties-1"><i class="fa fa-check"></i><b>10.4.1</b> Properties</a></li>
<li class="chapter" data-level="10.4.2" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-simple-hypotheses-the-neyman-pearson-lemma"><i class="fa fa-check"></i><b>10.4.2</b> Optimality for Simple Hypotheses: The Neyman-Pearson Lemma</a></li>
<li class="chapter" data-level="10.4.3" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-one-sided-hypotheses-the-karlin-rubin-theorem"><i class="fa fa-check"></i><b>10.4.3</b> Optimality for One-Sided Hypotheses: The Karlin-Rubin Theorem</a></li>
<li class="chapter" data-level="10.4.4" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#optimality-for-two-sided-hypotheses."><i class="fa fa-check"></i><b>10.4.4</b> Optimality for Two-Sided Hypotheses.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="hypothesis-tests-finite-samples.html"><a href="hypothesis-tests-finite-samples.html#nuisance-parameters"><i class="fa fa-check"></i><b>10.5</b> Nuisance Parameters</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Tests: Asymptotics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#wald-test"><i class="fa fa-check"></i><b>11.1</b> Wald Test</a></li>
<li class="chapter" data-level="11.2" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#score-test"><i class="fa fa-check"></i><b>11.2</b> Score Test</a></li>
<li class="chapter" data-level="11.3" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>11.3</b> Likelihood Ratio Test</a></li>
<li class="chapter" data-level="11.4" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#composite-null-hypotheses"><i class="fa fa-check"></i><b>11.4</b> Composite Null Hypotheses</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#multiple-parameters"><i class="fa fa-check"></i><b>11.4.1</b> Multiple Parameters</a></li>
<li class="chapter" data-level="11.4.2" data-path="hypothesis-tests-asymptotics.html"><a href="hypothesis-tests-asymptotics.html#nuisance-parameters-1"><i class="fa fa-check"></i><b>11.4.2</b> Nuisance Parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>12</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="12.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#definition-1"><i class="fa fa-check"></i><b>12.1</b> Definition</a></li>
<li class="chapter" data-level="12.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#test-inversion"><i class="fa fa-check"></i><b>12.2</b> When You’ve Constructed a Hypothesis Test…</a></li>
<li class="chapter" data-level="12.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#when-youve-found-a-pivot-including-asymptotic-normality"><i class="fa fa-check"></i><b>12.3</b> When You’ve Found a Pivot (Including Asymptotic Normality)…</a></li>
<li class="chapter" data-level="12.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#when-all-you-have-is-a-distribution"><i class="fa fa-check"></i><b>12.4</b> When All You Have Is a Distribution…</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="random-processes.html"><a href="random-processes.html"><i class="fa fa-check"></i><b>13</b> Random Processes</a>
<ul>
<li class="chapter" data-level="13.1" data-path="random-processes.html"><a href="random-processes.html#branching-process"><i class="fa fa-check"></i><b>13.1</b> Branching Processes</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="random-processes.html"><a href="random-processes.html#random-variables-1"><i class="fa fa-check"></i><b>13.1.1</b> Random Variables</a></li>
<li class="chapter" data-level="13.1.2" data-path="random-processes.html"><a href="random-processes.html#probability-generating-function"><i class="fa fa-check"></i><b>13.1.2</b> Probability Generating Function</a></li>
<li class="chapter" data-level="13.1.3" data-path="random-processes.html"><a href="random-processes.html#finding-the-pgf-of-a-branching-process"><i class="fa fa-check"></i><b>13.1.3</b> Finding the PGF of a Branching Process</a></li>
<li class="chapter" data-level="13.1.4" data-path="random-processes.html"><a href="random-processes.html#finding-the-probability-of-extinction-criticality-theorem"><i class="fa fa-check"></i><b>13.1.4</b> Finding the Probability of Extinction: Criticality Theorem</a></li>
<li class="chapter" data-level="13.1.5" data-path="random-processes.html"><a href="random-processes.html#example"><i class="fa fa-check"></i><b>13.1.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="random-processes.html"><a href="random-processes.html#poisson-processes"><i class="fa fa-check"></i><b>13.2</b> Poisson Processes</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="random-processes.html"><a href="random-processes.html#memorylessness-of-the-exponential"><i class="fa fa-check"></i><b>13.2.1</b> Memorylessness of the Exponential</a></li>
<li class="chapter" data-level="13.2.2" data-path="random-processes.html"><a href="random-processes.html#count-time-duality"><i class="fa fa-check"></i><b>13.2.2</b> Count-Time Duality</a></li>
<li class="chapter" data-level="13.2.3" data-path="random-processes.html"><a href="random-processes.html#poisson-distribution"><i class="fa fa-check"></i><b>13.2.3</b> Poisson Distribution</a></li>
<li class="chapter" data-level="13.2.4" data-path="random-processes.html"><a href="random-processes.html#exponential-distribution"><i class="fa fa-check"></i><b>13.2.4</b> Exponential Distribution</a></li>
<li class="chapter" data-level="13.2.5" data-path="random-processes.html"><a href="random-processes.html#example-1"><i class="fa fa-check"></i><b>13.2.5</b> Example</a></li>
<li class="chapter" data-level="13.2.6" data-path="random-processes.html"><a href="random-processes.html#merging-and-splitting"><i class="fa fa-check"></i><b>13.2.6</b> Merging and Splitting</a></li>
<li class="chapter" data-level="13.2.7" data-path="random-processes.html"><a href="random-processes.html#thinning"><i class="fa fa-check"></i><b>13.2.7</b> Thinning</a></li>
<li class="chapter" data-level="13.2.8" data-path="random-processes.html"><a href="random-processes.html#restarting"><i class="fa fa-check"></i><b>13.2.8</b> Restarting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Solving Statistical Problems</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="math-tricks" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Math Tricks<a href="math-tricks.html#math-tricks" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This chapter will cover highly specific mathematical techniques used to solve stats problems but themselves require no statistical knowledge, i.e…</p>
<ul>
<li>Exponential function as limits/series</li>
<li>Inductive integration by parts</li>
<li>substitution tricks for integration</li>
<li>binomial theorem</li>
<li>Gamma function properties</li>
<li>Matrices (determinants, jacobians, etc.)</li>
<li>Taylor Series (univariate and multivariate)</li>
<li>Lagrange multipliers? (Maybe save for MLEs)</li>
<li>Open versus closed intervals</li>
</ul>
<div id="combinatorics" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Combinatorics<a href="math-tricks.html#combinatorics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
</div>
<div id="binomial-and-multinomial-theorems" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Binomial and Multinomial Theorems<a href="math-tricks.html#binomial-and-multinomial-theorems" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <a href="https://en.wikipedia.org/wiki/Binomial_theorem">binomial theorem</a> states that</p>
<p><span class="math display">\[(x + y)^n = \sum_{k=0}^n {n\choose k}x^ky^{n-k}\]</span>
It can be used to prove that the pmf of a <a href="#binomial-distribution">Binomial Random Variable</a> sums to 1.</p>
<p>Analogously, the <a href="https://en.wikipedia.org/wiki/Multinomial_theorem">multinomial theorem</a> states</p>
<p><span class="math display">\[(x_1 + x_2 + ... + x_m)^n = \sum_{k_1, k_2,...,k_m \geq 0}\frac{n!}{k_1!k_2!...k_m!}\prod_{i=1}^nx_i^{k_i}\]</span>
provided <span class="math inline">\(\sum_{i=1}^m k_i = n\)</span>. It can be used to prove that the pmf of a <a href="#multinomial-distribution">Multinomial Random Variable</a> sums to 1.</p>
</div>
<div id="geometric-series" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Geometric Series<a href="math-tricks.html#geometric-series" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <strong>geometric series</strong> is a useful series convergence, defined as follows:</p>
<p><span class="math display">\[\sum_{x=0}^\infty ar^x = \frac{a}{1-r} \text{ for } |r| &lt; 1\]</span></p>
<p>One place it arises is computing the moments of the <a href="known-distributions.html#geometric-distribution">Geometric Distribution</a>.</p>
</div>
<div id="exponential-taylor" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Taylor Series for Exponential Function<a href="math-tricks.html#exponential-taylor" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Some distributions such as the Poisson rely on infinite sums. Often, we can simplify these infinite sums to an exponential by rewriting them using the following series convergence:</p>
<p><span class="math display">\[\sum_{x=0}^\infty \frac{\lambda^x}{x!} = \exp(\lambda)\]</span></p>
<p>This is the Taylor series for the exponential function, sometimes called the “exponential series”.</p>
</div>
<div id="taylors-formula" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Taylor’s Formula<a href="math-tricks.html#taylors-formula" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If the <span class="math inline">\((n+1)\)</span>th derivative of a function <span class="math inline">\(f\)</span> exists for all <span class="math inline">\(\xi \in (c, x)\)</span>, then</p>
<p><span class="math display">\[
f(x) = f(c) + f&#39;(c)(x-c) + \frac{f&#39;&#39;(c)}{2!}(x-c)^2 + ...\\
+ \frac{f^{(n)}(c)}{n!}(x - c)^n + R_n(x)
\]</span>
where</p>
<p><span class="math display">\[R_n(x) = \frac{f^{(n+1)}(\xi)}{(n+1)!}(x - c)^{n+1}\]</span></p>
<p>This can be found on page 550 of <span class="citation">Keisler (<a href="#ref-Keisler2013">2013</a>)</span>. Taylor’s formula is key to proofs of several important statistical theorems, including the <a href="#delta-method">Delta Method</a> and the <a href="point-estimators-asymptotics.html#point-estimators-asymptotics">asymptotic properties of the MLE</a>. Do note the following points of confusion:
- Although it is based on Taylor’s Formula, this is not identical to the infinite “Taylor Series” used to define functions like the exponential as mentioned previously. Taylor’s Formula terminates with <span class="math inline">\(R_n(x)\)</span>, a function defining the remaining error when approximating a function by a finite number of derivatives. This property is key, because showing that <span class="math inline">\(R_n(x) \rightarrow 0\)</span> allows asymptotic proofs to be developed.
- The aforementioned asymptotic proofs typically only rely on <span class="math inline">\(n = 1\)</span> or <span class="math inline">\(n = 2\)</span>, with the remainder appearing only after the second or third term.</p>
</div>
<div id="exponential-limit" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Exponential Limit<a href="math-tricks.html#exponential-limit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another way to express the exponential function is by the limit</p>
<p><span class="math display">\[\exp(x) = \lim_{n\rightarrow \infty}(1 + \frac{x}{n})^n\]</span></p>
</div>
<div id="ibp" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Integration by Parts<a href="math-tricks.html#ibp" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another technique, especially for computing moments, is integration by parts, defined by:</p>
<p><span class="math display">\[\int udv = uv - \int vdu\]</span></p>
<p>Integration by parts is typically used for products of functions. By setting <span class="math inline">\(u\)</span> equal to a function which has a finite number of nonzero derivatives (for example, <span class="math inline">\(x^k\)</span>), and <span class="math inline">\(v\)</span> equal to a function which does not (such as <span class="math inline">\(e^x\)</span>), this technique can be repeatedly applied to compute integration.</p>
<p>Of course, take caution: If both functions can be repeatedly differentiated infinitely, this may not work! However, it may be possible to use <strong>inductive integration by parts</strong> to prove that if we apply integration by parts infinitely, the result will yield a series which converges to some value <em>(where?)</em></p>
</div>
<div id="leibniz-rule" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Leibniz’s Rule<a href="math-tricks.html#leibniz-rule" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="theorem">
<p><span id="thm:unlabeled-div-1" class="theorem"><strong>Theorem 2.1  (Leibniz's Rule: Simple Version) </strong></span>If <span class="math inline">\(a, b\)</span> are constant and <span class="math inline">\(f(x, \theta)\)</span> is differentiable w.r.t to <span class="math inline">\(\theta\)</span>, then</p>
<p><span class="math display">\[\frac{d}{d\theta} \int_{a}^{b} f(x,\theta)dx = \int_a^b \frac{\partial}{\partial\theta}f(x,\theta)dx\]</span></p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-2" class="theorem"><strong>Theorem 2.2  (Leibniz's Rule: Complicated Version) </strong></span>If <span class="math inline">\(a(\theta)\)</span>, <span class="math inline">\(b(\theta)\)</span>, and <span class="math inline">\(f(x, \theta)\)</span> are differentiable w.r.t to <span class="math inline">\(\theta\)</span>, then</p>
<p><span class="math display">\[\frac{d}{d\theta}\int_{a(\theta)}^{b(\theta)}f(x,\theta)dx = f(b(\theta), \theta)\frac{d}{d\theta}b(\theta) - f(a(\theta), \theta)\frac{d}{d\theta}a(\theta) + \int_{a(\theta)}^{b(\theta)} \frac{\partial}{\partial\theta}f(x,\theta)dx\]</span></p>
</div>
</div>
<div id="fubinis-theorem" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Fubini’s Theorem<a href="math-tricks.html#fubinis-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One useful problem-solving technique is exchanging the order of integrals or infinite series to more easily solve an equation. But when can we do this?</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-3" class="theorem"><strong>Theorem 2.3  (Fubini's Theorem: Integrals) </strong></span><span class="math inline">\(\int_\mathcal{X}\int_\mathcal{Y}f(x,y)dydx = \int_\mathcal{Y}\int_\mathcal{X}f(x,y)dxdy\)</span> if <span class="math inline">\(\int_\mathcal{X}\int_\mathcal{Y}|f(x,y)|dydx &lt; \infty\)</span></p>
<p>that is, if the integral of its absolute value is finite.</p>
</div>
<div class="theorem">
<p><span id="thm:unlabeled-div-4" class="theorem"><strong>Theorem 2.4  (Fubini's Theorem: Infinite Series) </strong></span><span class="math inline">\(\sum_{m=1}^\infty\sum_{n=1}^\infty a_{m,n} = \sum_{n=1}^\infty\sum_{m=1}^\infty a_{m,n}\)</span> if <span class="math inline">\(\sum_{m=1}^\infty\sum_{n=1}^\infty |a_{m,n}| &lt; \infty\)</span></p>
<p>that is, if the original series is absolutely convergent</p>
</div>
</div>
<div id="gamma-function" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Gamma Function<a href="math-tricks.html#gamma-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Defined as</p>
<p><span class="math display">\[\Gamma(z) = \int_{0}^\infty t^{z-1}e^{-t}dt\]</span></p>
<p>the Gamma function commonly appears in the probability density function of several random variables, including the Gamma (duh!) and the Beta.</p>
<p>The most important property of <span class="math inline">\(\Gamma(z)\)</span> is that</p>
<p><span class="math display">\[\Gamma(z + 1) = z\Gamma(z)\]</span>
This is because we can substitute <span class="math inline">\(\Gamma(z) = \frac{\Gamma(z + 1)}{z}\)</span> to perform the <a href="#kernel-technique">Kernel Technique</a> on distributions involving the Gamma function in their pdf</p>
<p>As a corollary, when <span class="math inline">\(n\)</span> is an integer, <span class="math inline">\(\Gamma(n) = (n-1)!\)</span>.</p>
</div>
<div id="triangle-inequality" class="section level2 hasAnchor" number="2.11">
<h2><span class="header-section-number">2.11</span> Triangle Inequality<a href="math-tricks.html#triangle-inequality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The triangle inequality is defined as</p>
<p><span class="math display">\[|x + y| \leq |x| + |y|\]</span>
with <span class="math inline">\(|x + y| \leq |x| + |y|\)</span> unless <span class="math inline">\(x, y \geq 0\)</span>. This inequality is useful for proving <a href="moments.html#moment-bounds">moment bounds</a> as well as asymptotic convergence in <a href="point-estimators-asymptotics">Chapter 9</a> and <a href="hypothesis-tests-asymptotics">Chapter 11</a>.</p>
<p>A general trick for proving the triangular inequality that may be useful in other problems involving absolute value can be termed the “square trick” - noting <span class="math inline">\(x^2 = |x|^2\)</span>, we can first show the equality of a square, then take the square root to obtain <span class="math inline">\(|x|\)</span>. Here is a proof of the triangle inequality using this trick:</p>
<ol style="list-style-type: decimal">
<li><p>Note <span class="math inline">\((a + b)^2 = |a + b|^2 \leq 0\)</span></p></li>
<li><p>Rearrange <span class="math inline">\((a + b)^2\)</span> and</p></li>
</ol>
<p><span class="math display">\[
(a + b)^2 = a^2 + 2ab + b^2 = |a|^2 + 2ab + |b|^2\\
\leq |a|^2 + 2|a||b| + |b|^2 = (|a| + |b|)^2\\
\implies |a + b|^2 \leq (|a| + |b|)^2\\
\]</span>
3. Take the square root of the final implication to get <span class="math inline">\(|a + b| \leq |a| + |b|\)</span></p>
</div>
<div id="constrained-optimization" class="section level2 hasAnchor" number="2.12">
<h2><span class="header-section-number">2.12</span> Constrained Optimization<a href="math-tricks.html#constrained-optimization" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider a vector <span class="math inline">\(\theta = (\theta_1, \theta_2, ..., \theta_n)\)</span>. Suppose we want to maximize some function <span class="math inline">\(\mathcal{L}(\theta)\)</span>, <em>but</em> subject to a constraint <span class="math inline">\(g(\theta) = c\)</span>. How can this be accomplished using calculus? To do this, we rely on <strong>Lagrange Multipliers</strong>. The Lagrange function consists of the equation</p>
<p><span class="math display">\[L(\theta, \lambda) = \mathcal{L}(\theta) - \lambda(g(\theta) - c)\]</span>
Rather than optimizing <span class="math inline">\(\mathcal{L}(\theta)\)</span> using the First/Second Derivative test as we would have before, we instead optimize <span class="math inline">\(L(\theta, \lambda)\)</span> over <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\lambda\)</span>, finding where <span class="math inline">\(\nabla L(\theta, \lambda) = 0\)</span>. We can even add multiple <span class="math inline">\(\lambda_i, i = 1, 2,...\)</span> to account for multiple constraints.</p>
<p>Why does this work? Suppose we have some <span class="math inline">\(L(\theta_1, \lambda_2)\)</span> with <span class="math inline">\(g(\theta_1, \theta_2) = c\)</span>. Then, the location where <span class="math inline">\(L_x = L_y = L_\lambda = 0\)</span> occurs where</p>
<p><span class="math display">\[
\frac{\partial}{\partial\theta_1}L = \frac{\partial}{\partial \theta_1}\mathcal{L}(\theta) - \lambda\frac{\partial}{\partial \theta_1}g(\theta_1, \theta_2)\\
\frac{\partial}{\partial\theta_2}L = \frac{\partial}{\partial \theta_2}\mathcal{L}(\theta) - \lambda\frac{\partial}{\partial \theta_2}g(\theta_1, \theta_2)\\
\frac{\partial}{\partial\lambda}L = -g(\theta_1, \theta_2) + c = 0\\
\]</span>
That last equation guarantees that the constraint is satisfied during maximization. Within a problem, a system of equations will form in <span class="math inline">\(\lambda\)</span>; simply solve for each <span class="math inline">\(\theta_i\)</span> in <span class="math inline">\(\lambda\)</span>, solve for <span class="math inline">\(\lambda\)</span>, and plug in the solution for <span class="math inline">\(\lambda\)</span> into the earlier equations for <span class="math inline">\(\theta\)</span> to get the solution.</p>
<p>Within statistics, this technique arises in <a href="#mle">Maximum Likelihood Estimation</a>.</p>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Keisler2013" class="csl-entry">
Keisler, H Jerome. 2013. <em>Elementary Calculus: An Infinitesimal Approach</em>. Courier Corporation.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="probability.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02-math-tricks.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Solving-Statistical-Problems.pdf", "Solving-Statistical-Problems.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
